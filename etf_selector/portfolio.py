"""
ç»„åˆä¼˜åŒ–æ¨¡å—

å®ç°ç¬¬ä¸‰çº§ç­›é€‰ï¼šç›¸å…³æ€§åˆ†æå’Œä½ç›¸å…³æ€§ç»„åˆæ„å»º
æ ¸å¿ƒåŠŸèƒ½ï¼š
1. è®¡ç®—ETFæ”¶ç›Šç‡ç›¸å…³ç³»æ•°çŸ©é˜µ
2. åŸºäºç›¸å…³æ€§æ„å»ºåˆ†æ•£åŒ–ç»„åˆ
3. è€ƒè™‘è¡Œä¸šåˆ†æ•£å’Œæƒé‡å¹³è¡¡
4. æä¾›ç»„åˆé£é™©åº¦é‡
"""
from typing import Dict, List, Tuple, Optional
from datetime import datetime
from pathlib import Path
import warnings

import numpy as np
import pandas as pd

from .data_loader import ETFDataLoader
from .config import IndustryKeywords


class PortfolioOptimizer:
    """ç»„åˆä¼˜åŒ–å™¨

    åŸºäºç›¸å…³æ€§åˆ†ææ„å»ºä½ç›¸å…³æ€§ã€åˆ†æ•£åŒ–çš„ETFç»„åˆ

    Example:
        >>> optimizer = PortfolioOptimizer()
        >>> final_portfolio = optimizer.optimize_portfolio(
        ...     etf_candidates,
        ...     max_correlation=0.7,
        ...     target_size=20
        >>> )
        >>> print(f"ä¼˜åŒ–åç»„åˆ: {len(final_portfolio)} åªETF")
    """

    def __init__(
        self,
        data_loader: Optional[ETFDataLoader] = None,
        data_dir: str = 'data/csv'
    ):
        """åˆå§‹åŒ–ç»„åˆä¼˜åŒ–å™¨

        Args:
            data_loader: æ•°æ®åŠ è½½å™¨ï¼Œé»˜è®¤Noneè‡ªåŠ¨åˆ›å»º
            data_dir: æ•°æ®ç›®å½•ï¼Œä»…åœ¨data_loaderä¸ºNoneæ—¶ä½¿ç”¨
        """
        self.data_loader = data_loader if data_loader is not None else ETFDataLoader(data_dir)
        self.industry_classifier = IndustryKeywords()

        # ç¼“å­˜æ”¶ç›Šç‡æ•°æ®
        self._returns_cache = {}

    def calculate_returns_matrix(
        self,
        etf_codes: List[str],
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        min_periods: int = 100
    ) -> pd.DataFrame:
        """è®¡ç®—ETFæ”¶ç›Šç‡çŸ©é˜µ

        Args:
            etf_codes: ETFä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            min_periods: æœ€å°æ•°æ®æœŸæ•°ï¼Œå°‘äºæ­¤å€¼çš„ETFå°†è¢«è·³è¿‡

        Returns:
            æ”¶ç›Šç‡çŸ©é˜µDataFrameï¼Œindexä¸ºæ—¥æœŸï¼Œcolumnsä¸ºETFä»£ç 
        """
        returns_dict = {}

        for ts_code in etf_codes:
            try:
                # åŠ è½½ETFæ—¥çº¿æ•°æ®
                data = self.data_loader.load_etf_daily(
                    ts_code, start_date=start_date, end_date=end_date, use_adj=True
                )

                if len(data) < min_periods:
                    continue

                # è®¡ç®—æ—¥æ”¶ç›Šç‡
                returns = data['adj_close'].pct_change().dropna()

                if len(returns) < min_periods:
                    continue

                returns_dict[ts_code] = returns

            except (FileNotFoundError, ValueError, KeyError) as e:
                warnings.warn(f"åŠ è½½ {ts_code} æ”¶ç›Šç‡æ•°æ®å¤±è´¥: {e}")
                continue

        if not returns_dict:
            return pd.DataFrame()

        # æ„å»ºæ”¶ç›Šç‡çŸ©é˜µï¼Œå¯¹é½æ—¥æœŸ
        returns_df = pd.DataFrame(returns_dict)

        # åˆ é™¤å…¨ä¸ºNaNçš„æ—¥æœŸ
        returns_df = returns_df.dropna(how='all')

        return returns_df

    def calculate_correlation_matrix(self, returns_df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ

        Args:
            returns_df: æ”¶ç›Šç‡çŸ©é˜µ

        Returns:
            ç›¸å…³ç³»æ•°çŸ©é˜µDataFrame
        """
        if returns_df.empty:
            return pd.DataFrame()

        # è®¡ç®—Pearsonç›¸å…³ç³»æ•°
        correlation_matrix = returns_df.corr()

        # å°†å¯¹è§’çº¿è®¾ä¸º0ï¼ˆé¿å…è‡ªç›¸å…³å½±å“ï¼‰
        np.fill_diagonal(correlation_matrix.values, 0)

        return correlation_matrix

    def adaptive_deduplication(
        self,
        etf_candidates: List[Dict],
        target_size: int = 20,
        min_ratio: float = 0.8,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        verbose: bool = True
    ) -> List[Dict]:
        """æ™ºèƒ½å»é‡ï¼šåŠ¨æ€è°ƒæ•´ç›¸å…³æ€§é˜ˆå€¼ï¼Œç¡®ä¿ç›®æ ‡æ•°é‡

        è®¾è®¡ç­–ç•¥ï¼š
        1. ä»ä¸¥æ ¼é˜ˆå€¼(0.98)å¼€å§‹å»é‡
        2. å¦‚æœå»é‡åæ•°é‡ä¸è¶³ï¼Œé€æ­¥æ”¾å®½é˜ˆå€¼
        3. ä¼˜å…ˆä¿ç•™ä¸åŒè¡Œä¸šå’Œæ”¶ç›Šå›æ’¤æ¯”æ›´é«˜çš„ETF
        4. ç¡®ä¿æœ€ç»ˆæ•°é‡â‰¥target_size * min_ratio

        Args:
            etf_candidates: ETFå€™é€‰åˆ—è¡¨
            target_size: ç›®æ ‡ç»„åˆå¤§å°
            min_ratio: æœ€å°ä¿ç•™æ¯”ä¾‹ (0.8è¡¨ç¤ºè‡³å°‘ä¿ç•™80%ç›®æ ‡æ•°é‡)
            start_date: æ”¶ç›Šç‡è®¡ç®—å¼€å§‹æ—¥æœŸ
            end_date: æ”¶ç›Šç‡è®¡ç®—ç»“æŸæ—¥æœŸ
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

        Returns:
            å»é‡åçš„ETFåˆ—è¡¨
        """
        if len(etf_candidates) <= target_size * min_ratio:
            if verbose:
                print(f"  âš ï¸ å€™é€‰æ•°é‡({len(etf_candidates)})å·²å°‘äºæœ€å°è¦æ±‚ï¼Œè·³è¿‡å»é‡")
            return etf_candidates

        min_required = max(int(target_size * min_ratio), 1)

        if verbose:
            print(f"ğŸ§¹ æ™ºèƒ½å»é‡å¼€å§‹")
            print(f"  ğŸ“Š åŸå§‹å€™é€‰æ•°: {len(etf_candidates)}")
            print(f"  ğŸ¯ ç›®æ ‡æ•°é‡: {target_size}, æœ€å°ä¿ç•™: {min_required}")

        # è·å–ETFä»£ç å’Œè®¡ç®—æ”¶ç›Šç‡çŸ©é˜µ
        etf_codes = [etf['ts_code'] for etf in etf_candidates]
        returns_df = self.calculate_returns_matrix(
            etf_codes, start_date=start_date, end_date=end_date
        )

        if returns_df.empty:
            if verbose:
                print("  âŒ æ— æ³•è·å–æ”¶ç›Šç‡æ•°æ®ï¼Œè·³è¿‡å»é‡")
            return etf_candidates

        correlation_matrix = self.calculate_correlation_matrix(returns_df)

        if correlation_matrix.empty:
            return etf_candidates

        # åŠ¨æ€é˜ˆå€¼å»é‡
        thresholds = [0.98, 0.95, 0.92, 0.90]  # ä»ä¸¥æ ¼åˆ°å®½æ¾

        for i, threshold in enumerate(thresholds):
            deduplicated = self._remove_duplicates_by_correlation(
                etf_candidates, correlation_matrix, threshold, verbose=(verbose and i==0)
            )

            if len(deduplicated) >= min_required:
                if verbose:
                    print(f"  âœ… é˜ˆå€¼ {threshold} å»é‡æˆåŠŸ: {len(deduplicated)} åªETF")
                    removed_count = len(etf_candidates) - len(deduplicated)
                    if removed_count > 0:
                        print(f"  ğŸ—‘ï¸ ç§»é™¤é‡å¤ETF: {removed_count} åª")
                return deduplicated
            elif verbose:
                print(f"  âš ï¸ é˜ˆå€¼ {threshold} å»é‡åä»…å‰© {len(deduplicated)} åªï¼Œç»§ç»­æ”¾å®½...")

        # å¦‚æœæ‰€æœ‰é˜ˆå€¼éƒ½æ— æ³•æ»¡è¶³ï¼Œè¿”å›åŸå§‹å€™é€‰ï¼ˆä¿åº•ç­–ç•¥ï¼‰
        if verbose:
            print(f"  âŒ æ‰€æœ‰é˜ˆå€¼éƒ½æ— æ³•æ»¡è¶³æœ€å°æ•°é‡è¦æ±‚ï¼Œè¿”å›åŸå§‹å€™é€‰")
        return etf_candidates

    def _remove_duplicates_by_correlation(
        self,
        etf_candidates: List[Dict],
        correlation_matrix: pd.DataFrame,
        threshold: float = 0.95,
        verbose: bool = False
    ) -> List[Dict]:
        """åŸºäºç›¸å…³ç³»æ•°å»é™¤é‡å¤ETF

        ç®—æ³•é€»è¾‘ï¼š
        1. æ‰¾å‡ºæ‰€æœ‰ç›¸å…³æ€§>é˜ˆå€¼çš„ETFå¯¹
        2. åœ¨é«˜ç›¸å…³ETFä¸­ï¼Œä¼˜å…ˆä¿ç•™ï¼š
           - ä¸åŒè¡Œä¸šçš„ETFï¼ˆæå‡åˆ†æ•£åº¦ï¼‰
           - è´¨é‡æŒ‡æ ‡æ›´é«˜çš„ETFï¼ˆä¼˜å…ˆä½¿ç”¨return_dd_ratioï¼Œæ— åæ¨¡å¼ä¸‹ä½¿ç”¨final_scoreï¼‰
        3. è¿”å›å»é‡åçš„ETFåˆ—è¡¨

        **å…¼å®¹æ€§**:
        - å¯ç”¨åŒå‡çº¿å›æµ‹æ—¶ï¼šä½¿ç”¨ return_dd_ratio ä½œä¸ºè´¨é‡æŒ‡æ ‡
        - æ— åè¯„åˆ†æ¨¡å¼æ—¶ï¼šä½¿ç”¨ final_score ä½œä¸ºè´¨é‡æŒ‡æ ‡

        Args:
            etf_candidates: ETFå€™é€‰åˆ—è¡¨
            correlation_matrix: ç›¸å…³ç³»æ•°çŸ©é˜µ
            threshold: ç›¸å…³æ€§é˜ˆå€¼
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

        Returns:
            å»é‡åçš„ETFåˆ—è¡¨
        """
        if len(etf_candidates) <= 1:
            return etf_candidates

        # åˆ›å»ºETFæ˜ å°„
        etf_dict = {etf['ts_code']: etf for etf in etf_candidates}
        to_remove = set()
        duplicate_pairs = []

        # æ‰¾å‡ºé«˜ç›¸å…³ETFå¯¹
        for i, etf_i in enumerate(etf_candidates):
            if etf_i['ts_code'] in to_remove:
                continue

            for j, etf_j in enumerate(etf_candidates[i+1:], i+1):
                if etf_j['ts_code'] in to_remove:
                    continue

                try:
                    corr = correlation_matrix.loc[etf_i['ts_code'], etf_j['ts_code']]
                    if corr > threshold:
                        duplicate_pairs.append((etf_i, etf_j, corr))
                except (KeyError, ValueError):
                    continue

        if verbose and duplicate_pairs:
            print(f"    å‘ç° {len(duplicate_pairs)} å¯¹é«˜ç›¸å…³ETF (ç›¸å…³æ€§ > {threshold})")

        # å¤„ç†æ¯å¯¹é‡å¤ETFï¼Œå†³å®šä¿ç•™å“ªä¸€ä¸ª
        for etf_i, etf_j, corr in duplicate_pairs:
            if etf_i['ts_code'] in to_remove or etf_j['ts_code'] in to_remove:
                continue

            # å†³ç­–é€»è¾‘ï¼š
            # 1. ä¼˜å…ˆä¿ç•™ä¸åŒè¡Œä¸šçš„ï¼ˆæå‡è¡Œä¸šåˆ†æ•£åº¦ï¼‰
            # 2. åŒè¡Œä¸šåˆ™ä¿ç•™è´¨é‡æŒ‡æ ‡æ›´é«˜çš„ï¼ˆä¼˜å…ˆä½¿ç”¨return_dd_ratioï¼Œæ— åæ¨¡å¼ä¸‹ä½¿ç”¨final_scoreï¼‰

            industry_i = etf_i.get('industry', 'å…¶ä»–')
            industry_j = etf_j.get('industry', 'å…¶ä»–')
            ret_dd_i = etf_i.get('return_dd_ratio', np.nan)
            ret_dd_j = etf_j.get('return_dd_ratio', np.nan)

            # å¦‚æœreturn_dd_ratioéƒ½æ˜¯nanï¼Œä½¿ç”¨final_scoreä½œä¸ºåå¤‡
            if pd.isna(ret_dd_i) and pd.isna(ret_dd_j):
                ret_dd_i = etf_i.get('final_score', 0)
                ret_dd_j = etf_j.get('final_score', 0)
                metric_name = "è¯„åˆ†"  # ç”¨äºæ—¥å¿—è¾“å‡º
            elif pd.isna(ret_dd_i):
                ret_dd_i = -999  # æ— æ•ˆå€¼æ’å
                metric_name = "æ”¶ç›Šå›æ’¤æ¯”"
            elif pd.isna(ret_dd_j):
                ret_dd_j = -999
                metric_name = "æ”¶ç›Šå›æ’¤æ¯”"
            else:
                metric_name = "æ”¶ç›Šå›æ’¤æ¯”"

            if industry_i != industry_j:
                # ä¸åŒè¡Œä¸šï¼Œæ£€æŸ¥å·²é€‰è¡Œä¸šåˆ†å¸ƒï¼Œé€‰æ‹©ç¨€ç¼ºè¡Œä¸šçš„ETF
                selected_industries = [
                    etf_dict[code].get('industry', 'å…¶ä»–')
                    for code in etf_dict.keys()
                    if code not in to_remove
                ]
                count_i = selected_industries.count(industry_i)
                count_j = selected_industries.count(industry_j)

                if count_i > count_j:
                    to_remove.add(etf_i['ts_code'])
                    if verbose:
                        print(f"    ç§»é™¤ {etf_i['ts_code']} ({industry_i}ï¼Œå·²æœ‰{count_i}åª) "
                              f"ä¿ç•™ {etf_j['ts_code']} ({industry_j}ï¼Œä»…{count_j}åª)")
                elif count_j > count_i:
                    to_remove.add(etf_j['ts_code'])
                    if verbose:
                        print(f"    ç§»é™¤ {etf_j['ts_code']} ({industry_j}ï¼Œå·²æœ‰{count_j}åª) "
                              f"ä¿ç•™ {etf_i['ts_code']} ({industry_i}ï¼Œä»…{count_i}åª)")
                else:
                    # è¡Œä¸šæ•°é‡ç›¸åŒï¼ŒæŒ‰æ”¶ç›Šå›æ’¤æ¯”é€‰æ‹©
                    if ret_dd_i >= ret_dd_j:
                        to_remove.add(etf_j['ts_code'])
                    else:
                        to_remove.add(etf_i['ts_code'])
            else:
                # åŒè¡Œä¸šï¼Œç›´æ¥æŒ‰è´¨é‡æŒ‡æ ‡é€‰æ‹©
                if ret_dd_i >= ret_dd_j:
                    to_remove.add(etf_j['ts_code'])
                    if verbose:
                        print(f"    ç§»é™¤ {etf_j['ts_code']} ({metric_name}:{ret_dd_j:.3f}) "
                              f"ä¿ç•™ {etf_i['ts_code']} ({metric_name}:{ret_dd_i:.3f})")
                else:
                    to_remove.add(etf_i['ts_code'])
                    if verbose:
                        print(f"    ç§»é™¤ {etf_i['ts_code']} ({metric_name}:{ret_dd_i:.3f}) "
                              f"ä¿ç•™ {etf_j['ts_code']} ({metric_name}:{ret_dd_j:.3f})")

        # è¿”å›å»é‡åçš„ETFåˆ—è¡¨
        deduplicated = [etf for etf in etf_candidates if etf['ts_code'] not in to_remove]
        return deduplicated

    def optimize_portfolio(
        self,
        etf_candidates: List[Dict],
        max_correlation: float = 0.7,
        target_size: int = 20,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        balance_industries: bool = True,
        enable_deduplication: bool = True,
        dedup_min_ratio: float = 0.8,
        verbose: bool = True
    ) -> List[Dict]:
        """ç»„åˆä¼˜åŒ–ï¼šæ„å»ºä½ç›¸å…³æ€§ã€åˆ†æ•£åŒ–ç»„åˆ

        Args:
            etf_candidates: ETFå€™é€‰åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ts_code, name, industryç­‰ä¿¡æ¯
            max_correlation: æœ€å¤§ç›¸å…³ç³»æ•°é˜ˆå€¼
            target_size: ç›®æ ‡ç»„åˆå¤§å°
            start_date: æ”¶ç›Šç‡è®¡ç®—å¼€å§‹æ—¥æœŸ
            end_date: æ”¶ç›Šç‡è®¡ç®—ç»“æŸæ—¥æœŸ
            balance_industries: æ˜¯å¦å¹³è¡¡è¡Œä¸šåˆ†å¸ƒ
            enable_deduplication: æ˜¯å¦å¯ç”¨æ™ºèƒ½å»é‡
            dedup_min_ratio: å»é‡åæœ€å°ä¿ç•™æ¯”ä¾‹
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

        Returns:
            ä¼˜åŒ–åçš„ETFç»„åˆåˆ—è¡¨ï¼ŒæŒ‰åŸæ’åºä¿æŒ
        """
        if len(etf_candidates) == 0:
            return []

        if verbose:
            print("ğŸ”§ ç¬¬ä¸‰çº§ä¼˜åŒ–ï¼šç›¸å…³æ€§åˆ†æå’Œç»„åˆæ„å»º")
            print(f"  ğŸ“Š å€™é€‰ETFæ•°é‡: {len(etf_candidates)}")
            print(f"  ğŸ¯ ç›®æ ‡ç»„åˆå¤§å°: {target_size}")
            print(f"  ğŸ“ˆ ç›¸å…³æ€§é˜ˆå€¼: < {max_correlation}")
            if enable_deduplication:
                print(f"  ğŸ§¹ æ™ºèƒ½å»é‡: å¯ç”¨ (æœ€å°ä¿ç•™æ¯”ä¾‹: {dedup_min_ratio:.1%})")

        # ç¬¬ä¸€æ­¥ï¼šæ™ºèƒ½å»é‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        working_candidates = etf_candidates
        if enable_deduplication:
            working_candidates = self.adaptive_deduplication(
                etf_candidates=etf_candidates,
                target_size=target_size,
                min_ratio=dedup_min_ratio,
                start_date=start_date,
                end_date=end_date,
                verbose=verbose
            )

        # ç¬¬äºŒæ­¥ï¼šè®¡ç®—æ”¶ç›Šç‡çŸ©é˜µå’Œç›¸å…³æ€§çŸ©é˜µ
        etf_codes = [etf['ts_code'] for etf in working_candidates]

        if verbose:
            print(f"  ğŸ“Š è®¡ç®—æ”¶ç›Šç‡çŸ©é˜µ...")

        returns_df = self.calculate_returns_matrix(
            etf_codes, start_date=start_date, end_date=end_date
        )

        if returns_df.empty:
            if verbose:
                print("  âŒ æ— æ³•è·å–è¶³å¤Ÿçš„æ”¶ç›Šç‡æ•°æ®")
            return working_candidates[:target_size]  # é™çº§åˆ°ç›´æ¥æˆªå–

        # è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
        correlation_matrix = self.calculate_correlation_matrix(returns_df)

        if correlation_matrix.empty:
            return working_candidates[:target_size]

        if verbose:
            print(f"  âœ… ç›¸å…³æ€§çŸ©é˜µè®¡ç®—å®Œæˆ ({correlation_matrix.shape[0]}x{correlation_matrix.shape[1]})")

        # è´ªå¿ƒç®—æ³•é€‰æ‹©ä½ç›¸å…³æ€§ç»„åˆ
        selected_portfolio = self._greedy_selection(
            etf_candidates, correlation_matrix, max_correlation, target_size
        )

        if verbose:
            print(f"  ğŸ¯ è´ªå¿ƒé€‰æ‹©å®Œæˆ: {len(selected_portfolio)} åªETF")

        # è¡Œä¸šå¹³è¡¡ä¼˜åŒ–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if balance_industries and len(selected_portfolio) > target_size:
            selected_portfolio = self._balance_industries(selected_portfolio, target_size)
            if verbose:
                print(f"  âš–ï¸ è¡Œä¸šå¹³è¡¡å®Œæˆ: {len(selected_portfolio)} åªETF")

        # æ›´æ–°æ’åä¿¡æ¯
        for i, etf in enumerate(selected_portfolio):
            etf['final_rank'] = i + 1

        if verbose:
            print(f"  âœ… ç»„åˆä¼˜åŒ–å®Œæˆï¼æœ€ç»ˆé€‰å‡º {len(selected_portfolio)} åªETF")

            # æ‰“å°è¡Œä¸šåˆ†å¸ƒ
            industry_count = {}
            for etf in selected_portfolio:
                industry = etf.get('industry', 'å…¶ä»–')
                industry_count[industry] = industry_count.get(industry, 0) + 1

            print(f"  ğŸ“Š è¡Œä¸šåˆ†å¸ƒ: {dict(industry_count)}")

            # æ‰“å°å¹³å‡ç›¸å…³æ€§
            if len(selected_portfolio) > 1:
                portfolio_codes = [etf['ts_code'] for etf in selected_portfolio]
                portfolio_corr = correlation_matrix.loc[portfolio_codes, portfolio_codes]
                avg_corr = portfolio_corr.values[portfolio_corr.values != 0].mean()
                print(f"  ğŸ“ˆ å¹³å‡ç›¸å…³æ€§: {avg_corr:.3f}")

        return selected_portfolio

    def _greedy_selection(
        self,
        etf_candidates: List[Dict],
        correlation_matrix: pd.DataFrame,
        max_correlation: float,
        target_size: int
    ) -> List[Dict]:
        """è´ªå¿ƒç®—æ³•é€‰æ‹©ä½ç›¸å…³æ€§ETFç»„åˆ

        ç®—æ³•é€»è¾‘ï¼š
        1. é€‰æ‹©æ’åç¬¬ä¸€ä¸”åœ¨ç›¸å…³æ€§çŸ©é˜µä¸­çš„ETFä½œä¸ºèµ·ç‚¹
        2. ä¾æ¬¡é€‰æ‹©ä¸å·²é€‰ETFç›¸å…³æ€§æœ€ä½çš„å€™é€‰ETF
        3. å¦‚æœç›¸å…³æ€§è¶…è¿‡é˜ˆå€¼ï¼Œè·³è¿‡è¯¥ETF
        4. é‡å¤ç›´åˆ°è¾¾åˆ°ç›®æ ‡æ•°é‡

        **é²æ£’æ€§æ”¹è¿›**:
        - ç¡®ä¿åˆå§‹ETFåœ¨ç›¸å…³æ€§çŸ©é˜µä¸­ï¼ˆä¿®å¤åˆå§‹åŒ–å¤±è´¥bugï¼‰
        - æä¾›é™çº§ç­–ç•¥ï¼šç›¸å…³æ€§çŸ©é˜µä¸å®Œæ•´æ—¶ç›´æ¥æˆªå–å‰Nä¸ªETF

        Args:
            etf_candidates: ETFå€™é€‰åˆ—è¡¨ï¼ˆå·²æŒ‰æ”¶ç›Šå›æ’¤æ¯”æ’åºï¼‰
            correlation_matrix: ç›¸å…³ç³»æ•°çŸ©é˜µ
            max_correlation: æœ€å¤§ç›¸å…³ç³»æ•°é˜ˆå€¼
            target_size: ç›®æ ‡ç»„åˆå¤§å°

        Returns:
            é€‰ä¸­çš„ETFåˆ—è¡¨
        """
        selected = []

        # ç¬¬ä¸€æ­¥ï¼šæ‰¾åˆ°ç¬¬ä¸€ä¸ªåœ¨ç›¸å…³æ€§çŸ©é˜µä¸­çš„ETFä½œä¸ºèµ·ç‚¹
        for etf in etf_candidates:
            if etf['ts_code'] in correlation_matrix.index:
                selected.append(etf)
                break

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆETFï¼Œç›´æ¥è¿”å›ï¼ˆé™çº§ç­–ç•¥ï¼‰
        if len(selected) == 0:
            # è¿”å›å‰target_sizeä¸ªETFï¼ˆç›¸å…³æ€§ç­›é€‰å¤±è´¥æ—¶çš„é™çº§æ–¹æ¡ˆï¼‰
            return etf_candidates[:target_size]

        # ç¬¬äºŒæ­¥ï¼šè´ªå¿ƒé€‰æ‹©å‰©ä½™ETF
        for etf in etf_candidates:
            if len(selected) >= target_size:
                break

            ts_code = etf['ts_code']

            # è·³è¿‡å·²é€‰æ‹©çš„ETF
            if any(s['ts_code'] == ts_code for s in selected):
                continue

            # æ£€æŸ¥è¯¥ETFæ˜¯å¦åœ¨ç›¸å…³æ€§çŸ©é˜µä¸­
            if ts_code not in correlation_matrix.index:
                continue

            # è®¡ç®—ä¸å·²é€‰ETFçš„å¹³å‡ç›¸å…³æ€§
            selected_codes = [s['ts_code'] for s in selected]

            try:
                correlations = correlation_matrix.loc[ts_code, selected_codes]
                if isinstance(correlations, pd.Series):
                    avg_correlation = correlations.abs().mean()
                else:
                    # å•ä¸ªå€¼çš„æƒ…å†µ
                    avg_correlation = abs(correlations)

                # å¦‚æœå¹³å‡ç›¸å…³æ€§ä½äºé˜ˆå€¼ï¼ŒåŠ å…¥ç»„åˆ
                if avg_correlation < max_correlation:
                    selected.append(etf)

            except (KeyError, IndexError):
                # å¦‚æœå‡ºç°ç´¢å¼•é”™è¯¯ï¼Œè·³è¿‡è¯¥ETF
                continue

        return selected

    def _balance_industries(
        self,
        etf_list: List[Dict],
        target_size: int
    ) -> List[Dict]:
        """è¡Œä¸šå¹³è¡¡ä¼˜åŒ–

        åœ¨ä¿æŒæ”¶ç›Šå›æ’¤æ¯”æ’åºçš„åŸºç¡€ä¸Šï¼Œé€‚å½“å¹³è¡¡è¡Œä¸šåˆ†å¸ƒ

        Args:
            etf_list: ETFåˆ—è¡¨
            target_size: ç›®æ ‡ç»„åˆå¤§å°

        Returns:
            å¹³è¡¡åçš„ETFåˆ—è¡¨
        """
        if len(etf_list) <= target_size:
            return etf_list

        # ç»Ÿè®¡è¡Œä¸šåˆ†å¸ƒ
        industry_etfs = {}
        for etf in etf_list:
            industry = etf.get('industry', 'å…¶ä»–')
            if industry not in industry_etfs:
                industry_etfs[industry] = []
            industry_etfs[industry].append(etf)

        # è®¡ç®—è¡Œä¸šæƒé‡ç›®æ ‡ï¼ˆå‡åŒ€åˆ†å¸ƒï¼‰
        num_industries = len(industry_etfs)
        target_per_industry = target_size // num_industries
        remainder = target_size % num_industries

        balanced_portfolio = []

        # ä¸ºæ¯ä¸ªè¡Œä¸šåˆ†é…ETF
        industry_names = sorted(industry_etfs.keys())
        for i, industry in enumerate(industry_names):
            # è¯¥è¡Œä¸šçš„ç›®æ ‡æ•°é‡
            industry_target = target_per_industry + (1 if i < remainder else 0)
            industry_target = min(industry_target, len(industry_etfs[industry]))

            # é€‰æ‹©è¯¥è¡Œä¸šä¸­æ’åæœ€é«˜çš„ETF
            balanced_portfolio.extend(industry_etfs[industry][:industry_target])

        # æŒ‰åŸå§‹æ’åºé‡æ–°æ’åˆ—
        original_order = {etf['ts_code']: i for i, etf in enumerate(etf_list)}
        balanced_portfolio.sort(key=lambda x: original_order.get(x['ts_code'], float('inf')))

        return balanced_portfolio[:target_size]

    def analyze_portfolio_risk(
        self,
        portfolio: List[Dict],
        start_date: Optional[str] = None,
        end_date: Optional[str] = None
    ) -> Dict:
        """åˆ†æç»„åˆé£é™©ç‰¹å¾

        Args:
            portfolio: ETFç»„åˆåˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            é£é™©åˆ†æç»“æœå­—å…¸
        """
        if len(portfolio) == 0:
            return {}

        # è·å–ç»„åˆæ”¶ç›Šç‡çŸ©é˜µ
        portfolio_codes = [etf['ts_code'] for etf in portfolio]
        returns_df = self.calculate_returns_matrix(
            portfolio_codes, start_date=start_date, end_date=end_date
        )

        if returns_df.empty:
            return {'error': 'æ— æ³•è·å–ç»„åˆæ”¶ç›Šç‡æ•°æ®'}

        # è®¡ç®—é£é™©æŒ‡æ ‡
        correlation_matrix = self.calculate_correlation_matrix(returns_df)

        # å¹³å‡ç›¸å…³æ€§ï¼ˆå»é™¤å¯¹è§’çº¿ï¼‰
        correlation_values = correlation_matrix.values
        correlation_values = correlation_values[correlation_values != 0]  # å»é™¤å¯¹è§’çº¿0å€¼
        avg_correlation = np.mean(np.abs(correlation_values)) if len(correlation_values) > 0 else 0

        # ç»„åˆæ—¥æ”¶ç›Šç‡ï¼ˆç­‰æƒé‡ï¼‰
        portfolio_returns = returns_df.mean(axis=1)

        # å¹´åŒ–æ³¢åŠ¨ç‡
        portfolio_volatility = portfolio_returns.std() * np.sqrt(252)

        # æœ€å¤§ç›¸å…³æ€§
        max_correlation = np.max(np.abs(correlation_values)) if len(correlation_values) > 0 else 0

        # è¡Œä¸šåˆ†å¸ƒ
        industry_distribution = {}
        for etf in portfolio:
            industry = etf.get('industry', 'å…¶ä»–')
            industry_distribution[industry] = industry_distribution.get(industry, 0) + 1

        return {
            'portfolio_size': len(portfolio),
            'avg_correlation': avg_correlation,
            'max_correlation': max_correlation,
            'portfolio_volatility': portfolio_volatility,
            'industry_distribution': industry_distribution,
            'diversification_ratio': len(industry_distribution) / len(portfolio),
        }

    def export_portfolio_analysis(
        self,
        portfolio: List[Dict],
        output_path: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None
    ) -> None:
        """å¯¼å‡ºç»„åˆåˆ†ææŠ¥å‘Š

        Args:
            portfolio: ETFç»„åˆåˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            start_date: åˆ†æå¼€å§‹æ—¥æœŸ
            end_date: åˆ†æç»“æŸæ—¥æœŸ
        """
        # ç»„åˆåŸºæœ¬ä¿¡æ¯
        portfolio_df = pd.DataFrame(portfolio)

        # é£é™©åˆ†æ
        risk_analysis = self.analyze_portfolio_risk(
            portfolio, start_date=start_date, end_date=end_date
        )

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # å¯¼å‡ºç»„åˆè¯¦æƒ…
        timestamp = datetime.now().strftime('%Y%m%d')
        if not output_path.stem.endswith(timestamp[:8]):
            stem = output_path.stem + f'_{timestamp}'
            output_path = output_path.with_stem(stem)

        # å¯¼å‡ºCSV
        portfolio_df.to_csv(output_path, index=False, encoding='utf-8-sig')

        # å¯¼å‡ºåˆ†ææŠ¥å‘Š
        analysis_path = output_path.with_suffix('.analysis.txt')
        with open(analysis_path, 'w', encoding='utf-8') as f:
            f.write(f"ETFç»„åˆé£é™©åˆ†ææŠ¥å‘Š\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"åˆ†ææœŸé—´: {start_date or 'å…¨éƒ¨'} è‡³ {end_date or 'å…¨éƒ¨'}\n")
            f.write(f"{'='*50}\n\n")

            f.write(f"ç»„åˆè§„æ¨¡: {risk_analysis.get('portfolio_size', 0)} åªETF\n")
            f.write(f"å¹³å‡ç›¸å…³æ€§: {risk_analysis.get('avg_correlation', 0):.3f}\n")
            f.write(f"æœ€å¤§ç›¸å…³æ€§: {risk_analysis.get('max_correlation', 0):.3f}\n")
            f.write(f"ç»„åˆæ³¢åŠ¨ç‡: {risk_analysis.get('portfolio_volatility', 0):.2%}\n")
            f.write(f"è¡Œä¸šåˆ†æ•£åº¦: {risk_analysis.get('diversification_ratio', 0):.2f}\n\n")

            f.write("è¡Œä¸šåˆ†å¸ƒ:\n")
            industry_dist = risk_analysis.get('industry_distribution', {})
            for industry, count in sorted(industry_dist.items()):
                f.write(f"  {industry}: {count} åª\n")

        print(f"âœ… ç»„åˆåˆ†æå·²å¯¼å‡º:")
        print(f"  ğŸ“„ ç»„åˆè¯¦æƒ…: {output_path}")
        print(f"  ğŸ“Š é£é™©åˆ†æ: {analysis_path}")
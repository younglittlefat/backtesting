"""
æ ¸å¿ƒç­›é€‰å™¨

å®ç°ä¸‰çº§æ¼æ–—ETFç­›é€‰ç³»ç»Ÿï¼š
1. ç¬¬ä¸€çº§ï¼šåˆçº§ç­›é€‰ï¼ˆæµåŠ¨æ€§ã€ä¸Šå¸‚æ—¶é—´ï¼‰
2. ç¬¬äºŒçº§ï¼šæ ¸å¿ƒç­›é€‰ï¼ˆADXã€åŒå‡çº¿å›æµ‹ã€æ³¢åŠ¨ç‡ã€åŠ¨é‡ï¼‰
3. ç¬¬ä¸‰çº§ï¼šç»„åˆä¼˜åŒ–ï¼ˆç›¸å…³æ€§åˆ†æï¼‰
"""
import warnings
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

from .config import FilterConfig, IndustryKeywords
from .data_loader import ETFDataLoader
from .indicators import (
    calculate_rolling_adx_mean,
    calculate_volatility,
    calculate_momentum,
    calculate_excess_return,
    calculate_trend_r2,
    calculate_volume_trend,
    calculate_idr,
)
from .backtest_engine import calculate_backtest_metrics
from .unbiased_indicators import calculate_all_unbiased_indicators
from .scoring import (
    UnbiasedScorer,
    ScoringWeights,
    calculate_etf_scores,
    LegacyUnbiasedScorer,
    LegacyScoringWeights,
    calculate_legacy_etf_scores
)


class TrendETFSelector:
    """è¶‹åŠ¿ETFç­›é€‰å™¨

    ä½¿ç”¨ä¸‰çº§æ¼æ–—æ¨¡å‹ç³»ç»ŸåŒ–ç­›é€‰é€‚åˆè¶‹åŠ¿è·Ÿè¸ªç­–ç•¥çš„ETFæ ‡çš„æ± ã€‚

    ä¸‰çº§ç­›é€‰æµç¨‹ï¼š
    1. åˆçº§ç­›é€‰ï¼šæµåŠ¨æ€§ï¼ˆæ—¥å‡æˆäº¤é¢ï¼‰+ ä¸Šå¸‚æ—¶é—´
    2. æ ¸å¿ƒç­›é€‰ï¼šADXè¶‹åŠ¿å¼ºåº¦ + åŒå‡çº¿å›æµ‹ + æ³¢åŠ¨ç‡ + åŠ¨é‡
    3. ç»„åˆä¼˜åŒ–ï¼šç›¸å…³æ€§åˆ†æ + è¡Œä¸šåˆ†æ•£

    Example:
        >>> selector = TrendETFSelector()
        >>> selected_etfs = selector.run_pipeline(
        ...     start_date='2023-01-01',
        ...     end_date='2024-12-31'
        >>> )
        >>> print(f"ç­›é€‰å‡º {len(selected_etfs)} åªETF")
    """

    def __init__(
        self,
        config: Optional[FilterConfig] = None,
        data_loader: Optional[ETFDataLoader] = None,
        data_dir: str = 'data/csv'
    ):
        """åˆå§‹åŒ–ç­›é€‰å™¨

        Args:
            config: ç­›é€‰å‚æ•°é…ç½®ï¼Œé»˜è®¤Noneä½¿ç”¨é»˜è®¤é…ç½®
            data_loader: æ•°æ®åŠ è½½å™¨ï¼Œé»˜è®¤Noneè‡ªåŠ¨åˆ›å»º
            data_dir: æ•°æ®ç›®å½•ï¼Œä»…åœ¨data_loaderä¸ºNoneæ—¶ä½¿ç”¨
        """
        self.config = config if config is not None else FilterConfig()
        self.data_loader = data_loader if data_loader is not None else ETFDataLoader(data_dir)
        self.industry_classifier = IndustryKeywords()

        # ç­›é€‰ç»“æœå­˜å‚¨
        self.stage_results = {}
        self.metrics_cache = {}

    def run_pipeline(
        self,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        target_size: Optional[int] = None,
        verbose: bool = True,
        diversify_v2: bool = False,
        score_diff_threshold: float = 0.05
    ) -> List[Dict]:
        """æ‰§è¡Œå®Œæ•´ç­›é€‰æµç¨‹

        Args:
            start_date: å›æµ‹å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤Noneä½¿ç”¨å…¨éƒ¨æ•°æ®
            end_date: å›æµ‹ç»“æŸæ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤Noneä½¿ç”¨å…¨éƒ¨æ•°æ®
            target_size: ç›®æ ‡ç­›é€‰æ•°é‡ï¼Œé»˜è®¤Noneä½¿ç”¨configä¸­çš„é…ç½®
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
            diversify_v2: æ˜¯å¦å¯ç”¨V2åˆ†æ•£é€»è¾‘ï¼ˆP0: max pairwiseç›¸å…³æ€§, P1: Scoreä¼˜å…ˆå»é‡ï¼‰
            score_diff_threshold: V2å»é‡æ—¶Scoreå·®å¼‚é˜ˆå€¼ï¼ˆä»…diversify_v2ç”Ÿæ•ˆï¼‰

        Returns:
            ç­›é€‰ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
            - ts_code: ETFä»£ç 
            - name: ETFåç§°
            - industry: è¡Œä¸šåˆ†ç±»
            - stage1_rank, stage2_rank, final_rank: å„é˜¶æ®µæ’å
            - adx_mean, return_dd_ratio, volatility, momentum_3m: å…³é”®æŒ‡æ ‡
        """
        if target_size is None:
            target_size = self.config.target_portfolio_size

        if verbose:
            print(f"ğŸ¯ ETFè¶‹åŠ¿ç­›é€‰å™¨å¯åŠ¨")
            print(f"ğŸ“… æ•°æ®æœŸé—´: {start_date or 'å…¨éƒ¨'} è‡³ {end_date or 'å…¨éƒ¨'}")
            print(f"ğŸ² ç›®æ ‡æ•°é‡: {target_size} åª")
            print("=" * 60)

        # ç¬¬ä¸€çº§ï¼šåˆçº§ç­›é€‰
        stage1_etfs = self._stage1_basic_filter(verbose=verbose)
        self.stage_results['stage1'] = stage1_etfs

        if len(stage1_etfs) == 0:
            if verbose:
                print("âŒ ç¬¬ä¸€çº§ç­›é€‰åæ— å‰©ä½™æ ‡çš„")
            return []

        # ç¬¬äºŒçº§ï¼šæ ¸å¿ƒç­›é€‰
        stage2_etfs = self._stage2_trend_filter(
            stage1_etfs, start_date=start_date, end_date=end_date, verbose=verbose
        )
        self.stage_results['stage2'] = stage2_etfs

        if len(stage2_etfs) == 0:
            if verbose:
                print("âŒ ç¬¬äºŒçº§ç­›é€‰åæ— å‰©ä½™æ ‡çš„")
            return []

        # ç¬¬ä¸‰çº§ï¼šç»„åˆä¼˜åŒ–ï¼ˆåŒ…æ‹¬å»é‡å’Œç›¸å…³æ€§åˆ†æï¼‰
        try:
            from .portfolio import PortfolioOptimizer
            optimizer = PortfolioOptimizer(data_loader=self.data_loader)

            # æ€»æ˜¯æ‰§è¡Œç¬¬ä¸‰çº§ç­›é€‰ï¼ŒåŒ…æ‹¬å»é‡å’Œåˆ†æ•£åŒ–
            final_etfs = optimizer.optimize_portfolio(
                stage2_etfs,
                max_correlation=self.config.max_correlation,
                target_size=target_size,
                start_date=start_date,
                end_date=end_date,
                enable_deduplication=self.config.enable_deduplication,
                dedup_min_ratio=self.config.dedup_min_ratio,
                verbose=verbose,
                diversify_v2=diversify_v2,
                score_diff_threshold=score_diff_threshold,
                dedup_thresholds=self.config.dedup_thresholds
            )
        except ImportError:
            if verbose:
                print("  âš ï¸ ç»„åˆä¼˜åŒ–æ¨¡å—ä¸å¯ç”¨ï¼Œç›´æ¥ä½¿ç”¨å‰Nä¸ªç»“æœ")
            final_etfs = stage2_etfs[:target_size]

        self.stage_results['final'] = final_etfs

        if verbose:
            print(f"âœ… ç­›é€‰å®Œæˆï¼æœ€ç»ˆé€‰å‡º {len(final_etfs)} åªETF")
            print("=" * 60)

        return final_etfs

    def _stage1_basic_filter(self, verbose: bool = True) -> List[str]:
        """ç¬¬ä¸€çº§ï¼šåˆçº§ç­›é€‰ï¼ˆæµåŠ¨æ€§ + ä¸Šå¸‚æ—¶é—´ï¼‰

        Args:
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

        Returns:
            é€šè¿‡åˆçº§ç­›é€‰çš„ETFä»£ç åˆ—è¡¨
        """
        if verbose:
            print("ğŸ” ç¬¬ä¸€çº§ç­›é€‰ï¼šæµåŠ¨æ€§ + ä¸Šå¸‚æ—¶é—´")

        # åŠ è½½åŸºæœ¬ä¿¡æ¯ï¼ˆåªåŠ è½½è‚¡ç¥¨å‹ETFï¼‰
        basic_info = self.data_loader.load_basic_info(fund_type='è‚¡ç¥¨å‹')
        initial_count = len(basic_info)

        if verbose:
            print(f"  ğŸ“Š åˆå§‹è‚¡ç¥¨å‹ETFæ•°é‡: {initial_count}")

        passed_etfs = []
        liquidity_failed = 0
        listing_failed = 0
        data_failed = 0

        for _, row in basic_info.iterrows():
            ts_code = row['ts_code']

            try:
                # 1. ä¸Šå¸‚æ—¶é—´ç­›é€‰
                list_date, days_since_listing = self.data_loader.get_etf_listing_info(
                    ts_code, basic_info
                )

                if days_since_listing < self.config.min_listing_days:
                    listing_failed += 1
                    continue

                # 2. æµåŠ¨æ€§ç­›é€‰
                avg_turnover = self.data_loader.calculate_avg_turnover(
                    ts_code, lookback_days=self.config.turnover_lookback_days
                )

                if avg_turnover is None or avg_turnover < self.config.min_turnover:
                    liquidity_failed += 1
                    continue

                passed_etfs.append(ts_code)

            except (FileNotFoundError, ValueError):
                data_failed += 1
                continue

        if verbose:
            print(f"  âŒ ä¸Šå¸‚æ—¶é—´ä¸è¶³(<{self.config.min_listing_days}å¤©): {listing_failed}")
            print(f"  âŒ æµåŠ¨æ€§ä¸è¶³(<{self.config.min_turnover/1e8:.1f}äº¿): {liquidity_failed}")
            print(f"  âŒ æ•°æ®ç¼ºå¤±æˆ–å¼‚å¸¸: {data_failed}")
            print(f"  âœ… é€šè¿‡ç¬¬ä¸€çº§ç­›é€‰: {len(passed_etfs)}")
            print(f"  ğŸ“‰ ç­›é€‰ç‡: {len(passed_etfs)/initial_count:.1%}")

        return passed_etfs

    def _stage2_trend_filter(
        self,
        etf_codes: List[str],
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        verbose: bool = True
    ) -> List[Dict]:
        """ç¬¬äºŒçº§ï¼šæ ¸å¿ƒç­›é€‰ï¼ˆè¶‹åŠ¿æ€§é‡åŒ–æŒ‡æ ‡ï¼‰

        Args:
            etf_codes: é€šè¿‡ç¬¬ä¸€çº§ç­›é€‰çš„ETFä»£ç åˆ—è¡¨
            start_date: å›æµ‹å¼€å§‹æ—¥æœŸ
            end_date: å›æµ‹ç»“æŸæ—¥æœŸ
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

        Returns:
            æŒ‰æ”¶ç›Šå›æ’¤æ¯”æ’åºçš„ETFä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
            - ts_code, name, industry
            - adx_mean, return_dd_ratio, volatility, momentum_3m, momentum_12m
        """
        use_ma_filter = self.config.enable_ma_backtest_filter

        if verbose:
            print("ğŸ§® ç¬¬äºŒçº§ç­›é€‰ï¼šè¶‹åŠ¿æ€§é‡åŒ–åˆ†æ")
            print(f"  ğŸ“Š å¾…åˆ†æETFæ•°é‡: {len(etf_codes)}")

        metrics_list = []
        basic_info = self.data_loader.load_basic_info(fund_type=None)  # åŠ è½½å…¨éƒ¨ä»¥è·å–åç§°
        benchmark_close = None

        if self.config.enable_unbiased_scoring and self.config.benchmark_ts_code:
            try:
                benchmark_data = self.data_loader.load_etf_daily(
                    self.config.benchmark_ts_code,
                    start_date=start_date,
                    end_date=end_date,
                    use_adj=True
                )
                if 'adj_close' in benchmark_data.columns:
                    benchmark_close = benchmark_data['adj_close']
                elif 'close' in benchmark_data.columns:
                    benchmark_close = benchmark_data['close']
            except Exception as e:
                if verbose:
                    warnings.warn(f"åŠ è½½åŸºå‡† {self.config.benchmark_ts_code} æ•°æ®å¤±è´¥ï¼Œè¶…é¢æ”¶ç›Šå°†è·³è¿‡: {e}")
                benchmark_close = None

        def combine_trend_quality(values: List[float]) -> float:
            valid_values = [v for v in values if not (pd.isna(v) or np.isnan(v))]
            if len(valid_values) == 0:
                return np.nan
            return float(np.mean(valid_values))

        for i, ts_code in enumerate(etf_codes):
            if verbose and (i + 1) % 100 == 0:
                print(f"  ğŸƒ è¿›åº¦: {i + 1}/{len(etf_codes)}")

            try:
                # åŠ è½½æ•°æ®
                data = self.data_loader.load_etf_daily(
                    ts_code, start_date=start_date, end_date=end_date, use_adj=True
                )
                price_series = data['adj_close']

                # æ•°æ®é•¿åº¦æ£€æŸ¥ï¼ˆéœ€è¦è¶³å¤Ÿçš„æ•°æ®è®¡ç®—æŒ‡æ ‡ï¼‰
                min_data_length = max(
                    self.config.ma_long + 10,  # åŒå‡çº¿éœ€è¦çš„æœ€å°é•¿åº¦
                    self.config.adx_period + self.config.adx_lookback_days // 4,  # ADXéœ€è¦çš„æœ€å°é•¿åº¦
                    self.config.trend_quality_window + 5,
                    self.config.excess_return_long_window + 5,
                    self.config.volume_long_window + 5,
                    100  # è‡³å°‘100å¤©
                )

                if len(data) < min_data_length:
                    continue

                # 1. ADXè¶‹åŠ¿å¼ºåº¦
                adx_mean = calculate_rolling_adx_mean(
                    data['adj_high'], data['adj_low'], data['adj_close'],
                    adx_period=self.config.adx_period,
                    window=min(self.config.adx_lookback_days, len(data))
                )

                if np.isnan(adx_mean):
                    continue

                if use_ma_filter:
                    # 2. åŒå‡çº¿å›æµ‹
                    backtest_metrics = calculate_backtest_metrics(
                        data, short=self.config.ma_short, long=self.config.ma_long, use_adj=True
                    )

                    annual_return = backtest_metrics['annual_return']
                    max_drawdown = backtest_metrics['max_drawdown']
                    return_dd_ratio = backtest_metrics['return_dd_ratio']
                else:
                    annual_return = np.nan
                    max_drawdown = np.nan
                    return_dd_ratio = np.nan

                # 3. æ³¢åŠ¨ç‡
                returns = data['adj_close'].pct_change().dropna()
                volatility = calculate_volatility(
                    returns, window=min(self.config.volatility_lookback_days, len(returns))
                )

                if np.isnan(volatility):
                    continue

                # 4. åŠ¨é‡
                momentum_periods = self.config.momentum_periods or [63, 252]
                momentum = calculate_momentum(data['adj_close'], periods=momentum_periods)
                momentum_3m = momentum.get('63d', np.nan)
                momentum_12m = momentum.get('252d', np.nan)

                # 5. æ–°å¢ï¼šæ— åæŒ‡æ ‡è®¡ç®—
                unbiased_indicators = {}
                if self.config.enable_unbiased_scoring:
                    try:
                        unbiased_indicators = calculate_all_unbiased_indicators(
                            close=data['adj_close'],
                            volume=data['volume'],
                            trend_window=self.config.trend_consistency_window,
                            efficiency_window=self.config.price_efficiency_window,
                            liquidity_window=self.config.liquidity_score_window
                        )
                    except Exception as e:
                        if verbose:
                            warnings.warn(f"è®¡ç®— {ts_code} æ— åæŒ‡æ ‡æ—¶å‡ºé”™: {e}")
                        unbiased_indicators = {
                            'trend_consistency': np.nan,
                            'price_efficiency': np.nan,
                            'liquidity_score': np.nan
                        }

                # 6. ç›¸å¯¹å¼ºå¼±ä¸è¶‹åŠ¿è´¨é‡
                excess_return_20d = calculate_excess_return(
                    price_series,
                    benchmark_close,
                    period=self.config.excess_return_short_window
                )
                excess_return_60d = calculate_excess_return(
                    price_series,
                    benchmark_close,
                    period=self.config.excess_return_long_window
                )
                trend_quality_r2 = calculate_trend_r2(
                    price_series,
                    window=self.config.trend_quality_window
                )
                volume_trend = calculate_volume_trend(
                    data['volume'],
                    short_window=self.config.volume_short_window,
                    long_window=self.config.volume_long_window
                )
                trend_quality = combine_trend_quality([
                    trend_quality_r2,
                    unbiased_indicators.get('trend_consistency', np.nan),
                    unbiased_indicators.get('price_efficiency', np.nan)
                ])

                # 7. IDRï¼ˆé£é™©è°ƒæ•´åè¶…é¢æ”¶ç›Šï¼‰
                idr = calculate_idr(
                    price_series,
                    benchmark_close,
                    period=self.config.excess_return_long_window
                )

                # åº”ç”¨ç­›é€‰æ¡ä»¶
                # æ³¢åŠ¨ç‡èŒƒå›´æ£€æŸ¥ï¼ˆå¯é€‰ï¼‰
                if not self.config.skip_stage2_range_filtering:
                    if volatility < self.config.min_volatility or volatility > self.config.max_volatility:
                        continue

                # åŠ¨é‡æ£€æŸ¥ï¼ˆ3ä¸ªæœˆåŠ¨é‡å¿…é¡»ä¸ºæ­£ï¼‰ï¼ˆå¯é€‰ï¼‰
                if not self.config.skip_stage2_range_filtering:
                    if np.isnan(momentum_3m) or momentum_3m <= 0:
                        continue

                # è·å–ETFåç§°å’Œè¡Œä¸šåˆ†ç±»
                etf_info = basic_info[basic_info['ts_code'] == ts_code]
                name = etf_info['name'].iloc[0] if len(etf_info) > 0 else ts_code
                industry = self.industry_classifier.classify(name)

                # å­˜å‚¨æŒ‡æ ‡
                metrics_list.append({
                    'ts_code': ts_code,
                    'name': name,
                    'industry': industry,
                    'adx_mean': adx_mean,
                    'annual_return': annual_return,
                    'max_drawdown': max_drawdown,
                    'return_dd_ratio': return_dd_ratio,
                    'volatility': volatility,
                    'momentum_3m': momentum_3m,
                    'momentum_12m': momentum_12m,
                    # æ–°å¢æ— åæŒ‡æ ‡
                    'trend_consistency': unbiased_indicators.get('trend_consistency', np.nan),
                    'price_efficiency': unbiased_indicators.get('price_efficiency', np.nan),
                    'liquidity_score': unbiased_indicators.get('liquidity_score', np.nan),
                    # æ–°å¢ä¼˜åŒ–åçš„è¯„åˆ†è¾“å…¥
                    'excess_return_20d': excess_return_20d,
                    'excess_return_60d': excess_return_60d,
                    'trend_quality': trend_quality,
                    'trend_quality_r2': trend_quality_r2,
                    'volume_trend': volume_trend,
                    'idr': idr,
                })

            except Exception as e:
                if verbose and isinstance(e, (FileNotFoundError, ValueError)):
                    # è¿™äº›æ˜¯é¢„æœŸçš„é”™è¯¯ï¼Œä¸éœ€è¦æ‰“å°å †æ ˆ
                    pass
                else:
                    warnings.warn(f"å¤„ç† {ts_code} æ—¶å‡ºé”™: {e}")
                continue

        if verbose:
            print(f"  âœ… è®¡ç®—å®Œæˆï¼Œè·å¾— {len(metrics_list)} åªæœ‰æ•ˆæ ‡çš„")

        if len(metrics_list) == 0:
            return []

        # è½¬ä¸ºDataFrameä¾¿äºæ’åºå’Œç­›é€‰
        df = pd.DataFrame(metrics_list)

        # å¦‚æœå¯ç”¨äº†è·³è¿‡äºŒçº§ç™¾åˆ†ä½ç­›é€‰é€‰é¡¹ï¼Œç›´æ¥è·³åˆ°æ’åºæ­¥éª¤
        if self.config.skip_stage2_percentile_filtering:
            if verbose:
                print("  âš ï¸ å·²è·³è¿‡ç¬¬äºŒçº§ç™¾åˆ†ä½ç­›é€‰ï¼ˆADXã€æ”¶ç›Šå›æ’¤æ¯”ï¼‰ï¼Œå°†ç›´æ¥æŒ‰è¯„åˆ†æ’åº")
        else:
            # ADXç­›é€‰ï¼šä¿ç•™å‰adx_percentile%çš„æ ‡çš„
            adx_threshold = np.percentile(df['adx_mean'], self.config.adx_percentile)
            df = df[df['adx_mean'] >= adx_threshold]

            if verbose:
                print(f"  ğŸ¯ ADXç­›é€‰(>{adx_threshold:.1f}): ä¿ç•™ {len(df)} åª")

            # æ”¶ç›Šå›æ’¤æ¯”ç­›é€‰ï¼šä¿ç•™å‰ret_dd_percentile%çš„æ ‡çš„ï¼ˆå¯é€‰ï¼‰
            if len(df) > 0 and use_ma_filter:
                ret_dd_threshold = np.percentile(df['return_dd_ratio'], self.config.ret_dd_percentile)
                df = df[df['return_dd_ratio'] >= ret_dd_threshold]

                if verbose:
                    print(f"  ğŸ“ˆ æ”¶ç›Šå›æ’¤æ¯”ç­›é€‰(>{ret_dd_threshold:.2f}): ä¿ç•™ {len(df)} åª")
            elif len(df) > 0 and not use_ma_filter and verbose:
                print("  âš ï¸ å·²ç¦ç”¨åŒå‡çº¿å›æµ‹è¿‡æ»¤ï¼Œè·³è¿‡æ”¶ç›Šå›æ’¤æ¯”ç­›é€‰")

        # æŒ‰æ”¶ç›Šå›æ’¤æ¯”é™åºæ’åº
        if use_ma_filter:
            df = df.sort_values('return_dd_ratio', ascending=False).reset_index(drop=True)
        else:
            # ä½¿ç”¨æ— åè¯„åˆ†ç³»ç»Ÿæ’åº
            if self.config.enable_unbiased_scoring:
                if self.config.use_optimized_score:
                    # åˆ›å»ºè¯„åˆ†å™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
                    scoring_weights = ScoringWeights(
                        core_trend_weight=self.config.core_trend_weight,
                        trend_quality_weight=self.config.trend_quality_weight,
                        strength_weight=self.config.strength_weight,
                        volume_weight=self.config.volume_weight,
                        idr_weight=self.config.idr_weight,
                        excess_return_20d_weight=self.config.excess_return_20d_weight,
                        excess_return_60d_weight=self.config.excess_return_60d_weight
                    )
                    scorer = UnbiasedScorer(scoring_weights)

                    df = calculate_etf_scores(
                        df,
                        scorer=scorer,
                        normalize_method='percentile'
                    )

                    if verbose:
                        weights_parts = [
                            f"è¶…é¢æ”¶ç›Š{self.config.core_trend_weight:.0%}",
                            f"è¶‹åŠ¿è´¨é‡{self.config.trend_quality_weight:.0%}",
                            f"ADX{self.config.strength_weight:.0%}",
                            f"èµ„é‡‘åŠ¨èƒ½{self.config.volume_weight:.0%}"
                        ]
                        if self.config.idr_weight > 0:
                            weights_parts.append(f"IDR{self.config.idr_weight:.0%}")
                        print(
                            "  ğŸ¯ å¯ç”¨æ— åè¯„åˆ†ç³»ç»Ÿï¼ˆä¼˜åŒ–ç‰ˆï¼‰ï¼š" +
                            " + ".join(weights_parts)
                        )
                else:
                    # åˆ›å»ºè¯„åˆ†å™¨ï¼ˆæ—§ç‰ˆï¼‰
                    scoring_weights = LegacyScoringWeights(
                        primary_weight=self.config.primary_weight,
                        secondary_weight=self.config.secondary_weight,
                        adx_weight=self.config.adx_score_weight,
                        trend_consistency_weight=self.config.trend_consistency_weight,
                        price_efficiency_weight=self.config.price_efficiency_weight,
                        liquidity_weight=self.config.liquidity_score_weight,
                        momentum_3m_weight=self.config.momentum_3m_score_weight,
                        momentum_12m_weight=self.config.momentum_12m_score_weight
                    )
                    scorer = LegacyUnbiasedScorer(scoring_weights)

                    df = calculate_legacy_etf_scores(
                        df,
                        scorer=scorer,
                        normalize_method='percentile'
                    )

                    if verbose:
                        print(
                            "  ğŸ¯ å¯ç”¨æ— åè¯„åˆ†ç³»ç»Ÿï¼ˆæ—§ç‰ˆï¼‰ï¼šä¸»è¦"
                            f"{self.config.primary_weight:.0%} + åŠ¨é‡{self.config.secondary_weight:.0%} "
                            f"(ADX/TC/æ•ˆç‡/æµåŠ¨æ€§: "
                            f"{self.config.adx_score_weight:.0%}/"
                            f"{self.config.trend_consistency_weight:.0%}/"
                            f"{self.config.price_efficiency_weight:.0%}/"
                            f"{self.config.liquidity_score_weight:.0%}; "
                            f"3M/12MåŠ¨é‡: "
                            f"{self.config.momentum_3m_score_weight:.0%}/"
                            f"{self.config.momentum_12m_score_weight:.0%})"
                        )
            else:
                # å›é€€åˆ°åŸæœ‰çš„åŠ¨é‡æ’åºï¼ˆä»…å½“ç¦ç”¨æ— åè¯„åˆ†æ—¶ï¼‰
                sort_columns = ['adx_mean', 'momentum_12m', 'momentum_3m']
                df = df.sort_values(
                    by=sort_columns, ascending=[False, False, False], na_position='last'
                ).reset_index(drop=True)

                if verbose:
                    print("  âš ï¸ ä½¿ç”¨ä¼ ç»Ÿæ’åºæ–¹å¼ï¼ˆå­˜åœ¨é€‰æ‹©æ€§åå·®é£é™©ï¼‰")

        # æ·»åŠ æ’åä¿¡æ¯
        df['stage2_rank'] = range(1, len(df) + 1)

        if verbose:
            print(f"  ğŸ† ç¬¬äºŒçº§ç­›é€‰å®Œæˆï¼Œå…± {len(df)} åªæ ‡çš„é€šè¿‡")
            if len(df) > 0:
                print(f"  ğŸ“Š ADXå‡å€¼èŒƒå›´: {df['adx_mean'].min():.1f} ~ {df['adx_mean'].max():.1f}")
                print(f"  ğŸ“Š æ³¢åŠ¨ç‡èŒƒå›´: {df['volatility'].min():.1%} ~ {df['volatility'].max():.1%}")

                # æ˜¾ç¤ºæ— åæŒ‡æ ‡ç»Ÿè®¡
                if self.config.enable_unbiased_scoring and 'final_score' in df.columns:
                    if self.config.use_optimized_score:
                        print(f"  ğŸ“Š è¶‹åŠ¿ä¸€è‡´æ€§: {df['trend_consistency'].min():.2f} ~ {df['trend_consistency'].max():.2f}")
                        print(f"  ğŸ“Š ä»·æ ¼æ•ˆç‡: {df['price_efficiency'].min():.2f} ~ {df['price_efficiency'].max():.2f}")
                        print(f"  ğŸ“Š è¶‹åŠ¿è´¨é‡(R^2èåˆ): {df['trend_quality'].min():.2f} ~ {df['trend_quality'].max():.2f}")
                        print(f"  ğŸ“Š æˆäº¤é‡è¶‹åŠ¿(20/60): {df['volume_trend'].min():.2f} ~ {df['volume_trend'].max():.2f}")
                        print(f"  ğŸ“Š è¶…é¢æ”¶ç›Š20æ—¥: {df['excess_return_20d'].min():.2%} ~ {df['excess_return_20d'].max():.2%}")
                        print(f"  ğŸ“Š è¶…é¢æ”¶ç›Š60æ—¥: {df['excess_return_60d'].min():.2%} ~ {df['excess_return_60d'].max():.2%}")
                        if 'idr' in df.columns:
                            print(f"  ğŸ“Š IDR(é£é™©è°ƒæ•´è¶…é¢æ”¶ç›Š): {df['idr'].min():.2f} ~ {df['idr'].max():.2f}")
                        print(f"  ğŸ“Š ç»¼åˆè¯„åˆ†: {df['final_score'].min():.2f} ~ {df['final_score'].max():.2f}")
                        weights_str = (
                            f"è¶…é¢æ”¶ç›Š{self.config.core_trend_weight:.0%}/"
                            f"è´¨é‡{self.config.trend_quality_weight:.0%}/"
                            f"ADX{self.config.strength_weight:.0%}/"
                            f"èµ„é‡‘{self.config.volume_weight:.0%}"
                        )
                        if self.config.idr_weight > 0:
                            weights_str += f"/IDR{self.config.idr_weight:.0%}"
                        print(f"  ğŸ“Š è¯„åˆ†æƒé‡: {weights_str}")
                    else:
                        print(f"  ğŸ“Š è¶‹åŠ¿ä¸€è‡´æ€§: {df['trend_consistency'].min():.2f} ~ {df['trend_consistency'].max():.2f}")
                        print(f"  ğŸ“Š ä»·æ ¼æ•ˆç‡: {df['price_efficiency'].min():.2f} ~ {df['price_efficiency'].max():.2f}")
                        print(f"  ğŸ“Š åŠ¨é‡3M: {df['momentum_3m'].min():.2%} ~ {df['momentum_3m'].max():.2%}")
                        print(f"  ğŸ“Š åŠ¨é‡12M: {df['momentum_12m'].min():.2%} ~ {df['momentum_12m'].max():.2%}")
                        print(f"  ğŸ“Š ç»¼åˆè¯„åˆ†: {df['final_score'].min():.2f} ~ {df['final_score'].max():.2f}")
                        print(
                            f"  ğŸ“Š è¯„åˆ†æƒé‡: ä¸»è¦{self.config.primary_weight:.0%}"
                            f"(ADX/TC/æ•ˆç‡/æµåŠ¨æ€§:"
                            f"{self.config.adx_score_weight:.0%}/"
                            f"{self.config.trend_consistency_weight:.0%}/"
                            f"{self.config.price_efficiency_weight:.0%}/"
                            f"{self.config.liquidity_score_weight:.0%}) + "
                            f"åŠ¨é‡{self.config.secondary_weight:.0%}"
                            f"(3M/12M:"
                            f"{self.config.momentum_3m_score_weight:.0%}/"
                            f"{self.config.momentum_12m_score_weight:.0%})"
                        )

                if use_ma_filter:
                    print(
                        f"  ğŸ“Š æ”¶ç›Šå›æ’¤æ¯”èŒƒå›´: "
                        f"{df['return_dd_ratio'].min():.2f} ~ {df['return_dd_ratio'].max():.2f}"
                    )
                elif not self.config.enable_unbiased_scoring:
                    print("  ğŸ“Š å·²ç¦ç”¨æ”¶ç›Šå›æ’¤æ¯”æ’åï¼Œç»“æœæŒ‰ADX+åŠ¨é‡æ’åº")

        return df.to_dict('records')

    def export_results(
        self,
        results: List[Dict],
        output_path: str,
        stage: str = 'final'
    ) -> None:
        """å¯¼å‡ºç­›é€‰ç»“æœåˆ°CSVæ–‡ä»¶

        Args:
            results: ç­›é€‰ç»“æœåˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            stage: ç­›é€‰é˜¶æ®µæ ‡è¯†ï¼ˆç”¨äºæ–‡ä»¶åï¼‰
        """
        if len(results) == 0:
            print(f"âŒ æ— ç»“æœå¯å¯¼å‡º")
            return

        df = pd.DataFrame(results)

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # æ ¼å¼åŒ–æµ®ç‚¹æ•°åˆ—ä¸º5ä½å°æ•°
        float_columns = df.select_dtypes(include=['float64', 'float32']).columns
        for col in float_columns:
            df[col] = df[col].apply(lambda x: f'{x:.5f}' if pd.notna(x) else '')

        # å¯¼å‡ºCSVï¼ˆç›´æ¥ä½¿ç”¨æŒ‡å®šçš„è·¯å¾„ï¼Œä¸æ·»åŠ æ—¶é—´æˆ³ï¼‰
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"âœ… ç»“æœå·²å¯¼å‡º: {output_path} ({len(df)} åªETF)")

    def get_summary_stats(self) -> Dict:
        """è·å–ç­›é€‰ç»Ÿè®¡æ‘˜è¦

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        stats = {}

        for stage, results in self.stage_results.items():
            if isinstance(results, list):
                if len(results) > 0 and isinstance(results[0], dict):
                    # ç¬¬äºŒçº§åŠä»¥åçš„ç»“æœ
                    df = pd.DataFrame(results)
                    stats[stage] = {
                        'count': len(df),
                        'avg_return_dd_ratio': df['return_dd_ratio'].mean() if 'return_dd_ratio' in df.columns else None,
                        'avg_adx': df['adx_mean'].mean() if 'adx_mean' in df.columns else None,
                        'avg_volatility': df['volatility'].mean() if 'volatility' in df.columns else None,
                    }
                else:
                    # ç¬¬ä¸€çº§ç»“æœï¼ˆåªæœ‰ä»£ç åˆ—è¡¨ï¼‰
                    stats[stage] = {'count': len(results)}

        return stats

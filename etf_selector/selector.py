"""
æ ¸å¿ƒç­›é€‰å™¨

å®ç°ä¸‰çº§æ¼æ–—ETFç­›é€‰ç³»ç»Ÿï¼š
1. ç¬¬ä¸€çº§ï¼šåˆçº§ç­›é€‰ï¼ˆæµåŠ¨æ€§ã€ä¸Šå¸‚æ—¶é—´ï¼‰
2. ç¬¬äºŒçº§ï¼šæ ¸å¿ƒç­›é€‰ï¼ˆADXã€åŒå‡çº¿å›æµ‹ã€æ³¢åŠ¨ç‡ã€åŠ¨é‡ï¼‰
3. ç¬¬ä¸‰çº§ï¼šç»„åˆä¼˜åŒ–ï¼ˆç›¸å…³æ€§åˆ†æï¼‰
"""
import warnings
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

from .config import FilterConfig, IndustryKeywords
from .data_loader import ETFDataLoader
from .indicators import calculate_rolling_adx_mean, calculate_volatility, calculate_momentum
from .backtest_engine import calculate_backtest_metrics


class TrendETFSelector:
    """è¶‹åŠ¿ETFç­›é€‰å™¨

    ä½¿ç”¨ä¸‰çº§æ¼æ–—æ¨¡å‹ç³»ç»ŸåŒ–ç­›é€‰é€‚åˆè¶‹åŠ¿è·Ÿè¸ªç­–ç•¥çš„ETFæ ‡çš„æ± ã€‚

    ä¸‰çº§ç­›é€‰æµç¨‹ï¼š
    1. åˆçº§ç­›é€‰ï¼šæµåŠ¨æ€§ï¼ˆæ—¥å‡æˆäº¤é¢ï¼‰+ ä¸Šå¸‚æ—¶é—´
    2. æ ¸å¿ƒç­›é€‰ï¼šADXè¶‹åŠ¿å¼ºåº¦ + åŒå‡çº¿å›æµ‹ + æ³¢åŠ¨ç‡ + åŠ¨é‡
    3. ç»„åˆä¼˜åŒ–ï¼šç›¸å…³æ€§åˆ†æ + è¡Œä¸šåˆ†æ•£

    Example:
        >>> selector = TrendETFSelector()
        >>> selected_etfs = selector.run_pipeline(
        ...     start_date='2023-01-01',
        ...     end_date='2024-12-31'
        >>> )
        >>> print(f"ç­›é€‰å‡º {len(selected_etfs)} åªETF")
    """

    def __init__(
        self,
        config: Optional[FilterConfig] = None,
        data_loader: Optional[ETFDataLoader] = None,
        data_dir: str = 'data/csv'
    ):
        """åˆå§‹åŒ–ç­›é€‰å™¨

        Args:
            config: ç­›é€‰å‚æ•°é…ç½®ï¼Œé»˜è®¤Noneä½¿ç”¨é»˜è®¤é…ç½®
            data_loader: æ•°æ®åŠ è½½å™¨ï¼Œé»˜è®¤Noneè‡ªåŠ¨åˆ›å»º
            data_dir: æ•°æ®ç›®å½•ï¼Œä»…åœ¨data_loaderä¸ºNoneæ—¶ä½¿ç”¨
        """
        self.config = config if config is not None else FilterConfig()
        self.data_loader = data_loader if data_loader is not None else ETFDataLoader(data_dir)
        self.industry_classifier = IndustryKeywords()

        # ç­›é€‰ç»“æœå­˜å‚¨
        self.stage_results = {}
        self.metrics_cache = {}

    def run_pipeline(
        self,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        target_size: Optional[int] = None,
        verbose: bool = True
    ) -> List[Dict]:
        """æ‰§è¡Œå®Œæ•´ç­›é€‰æµç¨‹

        Args:
            start_date: å›æµ‹å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤Noneä½¿ç”¨å…¨éƒ¨æ•°æ®
            end_date: å›æµ‹ç»“æŸæ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤Noneä½¿ç”¨å…¨éƒ¨æ•°æ®
            target_size: ç›®æ ‡ç­›é€‰æ•°é‡ï¼Œé»˜è®¤Noneä½¿ç”¨configä¸­çš„é…ç½®
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

        Returns:
            ç­›é€‰ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
            - ts_code: ETFä»£ç 
            - name: ETFåç§°
            - industry: è¡Œä¸šåˆ†ç±»
            - stage1_rank, stage2_rank, final_rank: å„é˜¶æ®µæ’å
            - adx_mean, return_dd_ratio, volatility, momentum_3m: å…³é”®æŒ‡æ ‡
        """
        if target_size is None:
            target_size = self.config.target_portfolio_size

        if verbose:
            print(f"ğŸ¯ ETFè¶‹åŠ¿ç­›é€‰å™¨å¯åŠ¨")
            print(f"ğŸ“… æ•°æ®æœŸé—´: {start_date or 'å…¨éƒ¨'} è‡³ {end_date or 'å…¨éƒ¨'}")
            print(f"ğŸ² ç›®æ ‡æ•°é‡: {target_size} åª")
            print("=" * 60)

        # ç¬¬ä¸€çº§ï¼šåˆçº§ç­›é€‰
        stage1_etfs = self._stage1_basic_filter(verbose=verbose)
        self.stage_results['stage1'] = stage1_etfs

        if len(stage1_etfs) == 0:
            if verbose:
                print("âŒ ç¬¬ä¸€çº§ç­›é€‰åæ— å‰©ä½™æ ‡çš„")
            return []

        # ç¬¬äºŒçº§ï¼šæ ¸å¿ƒç­›é€‰
        stage2_etfs = self._stage2_trend_filter(
            stage1_etfs, start_date=start_date, end_date=end_date, verbose=verbose
        )
        self.stage_results['stage2'] = stage2_etfs

        if len(stage2_etfs) == 0:
            if verbose:
                print("âŒ ç¬¬äºŒçº§ç­›é€‰åæ— å‰©ä½™æ ‡çš„")
            return []

        # ç¬¬ä¸‰çº§ï¼šç»„åˆä¼˜åŒ–ï¼ˆåŒ…æ‹¬å»é‡å’Œç›¸å…³æ€§åˆ†æï¼‰
        try:
            from .portfolio import PortfolioOptimizer
            optimizer = PortfolioOptimizer(data_loader=self.data_loader)

            # æ€»æ˜¯æ‰§è¡Œç¬¬ä¸‰çº§ç­›é€‰ï¼ŒåŒ…æ‹¬å»é‡å’Œåˆ†æ•£åŒ–
            final_etfs = optimizer.optimize_portfolio(
                stage2_etfs,
                max_correlation=0.7,
                target_size=target_size,
                start_date=start_date,
                end_date=end_date,
                enable_deduplication=True,  # å¯ç”¨æ™ºèƒ½å»é‡
                dedup_min_ratio=0.8,        # æœ€å°ä¿ç•™æ¯”ä¾‹80%
                verbose=verbose
            )
        except ImportError:
            if verbose:
                print("  âš ï¸ ç»„åˆä¼˜åŒ–æ¨¡å—ä¸å¯ç”¨ï¼Œç›´æ¥ä½¿ç”¨å‰Nä¸ªç»“æœ")
            final_etfs = stage2_etfs[:target_size]

        self.stage_results['final'] = final_etfs

        if verbose:
            print(f"âœ… ç­›é€‰å®Œæˆï¼æœ€ç»ˆé€‰å‡º {len(final_etfs)} åªETF")
            print("=" * 60)

        return final_etfs

    def _stage1_basic_filter(self, verbose: bool = True) -> List[str]:
        """ç¬¬ä¸€çº§ï¼šåˆçº§ç­›é€‰ï¼ˆæµåŠ¨æ€§ + ä¸Šå¸‚æ—¶é—´ï¼‰

        Args:
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

        Returns:
            é€šè¿‡åˆçº§ç­›é€‰çš„ETFä»£ç åˆ—è¡¨
        """
        if verbose:
            print("ğŸ” ç¬¬ä¸€çº§ç­›é€‰ï¼šæµåŠ¨æ€§ + ä¸Šå¸‚æ—¶é—´")

        # åŠ è½½åŸºæœ¬ä¿¡æ¯ï¼ˆåªåŠ è½½è‚¡ç¥¨å‹ETFï¼‰
        basic_info = self.data_loader.load_basic_info(fund_type='è‚¡ç¥¨å‹')
        initial_count = len(basic_info)

        if verbose:
            print(f"  ğŸ“Š åˆå§‹è‚¡ç¥¨å‹ETFæ•°é‡: {initial_count}")

        passed_etfs = []
        liquidity_failed = 0
        listing_failed = 0
        data_failed = 0

        for _, row in basic_info.iterrows():
            ts_code = row['ts_code']

            try:
                # 1. ä¸Šå¸‚æ—¶é—´ç­›é€‰
                list_date, days_since_listing = self.data_loader.get_etf_listing_info(
                    ts_code, basic_info
                )

                if days_since_listing < self.config.min_listing_days:
                    listing_failed += 1
                    continue

                # 2. æµåŠ¨æ€§ç­›é€‰
                avg_turnover = self.data_loader.calculate_avg_turnover(
                    ts_code, lookback_days=self.config.turnover_lookback_days
                )

                if avg_turnover is None or avg_turnover < self.config.min_turnover:
                    liquidity_failed += 1
                    continue

                passed_etfs.append(ts_code)

            except (FileNotFoundError, ValueError):
                data_failed += 1
                continue

        if verbose:
            print(f"  âŒ ä¸Šå¸‚æ—¶é—´ä¸è¶³(<{self.config.min_listing_days}å¤©): {listing_failed}")
            print(f"  âŒ æµåŠ¨æ€§ä¸è¶³(<{self.config.min_turnover/1e8:.1f}äº¿): {liquidity_failed}")
            print(f"  âŒ æ•°æ®ç¼ºå¤±æˆ–å¼‚å¸¸: {data_failed}")
            print(f"  âœ… é€šè¿‡ç¬¬ä¸€çº§ç­›é€‰: {len(passed_etfs)}")
            print(f"  ğŸ“‰ ç­›é€‰ç‡: {len(passed_etfs)/initial_count:.1%}")

        return passed_etfs

    def _stage2_trend_filter(
        self,
        etf_codes: List[str],
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        verbose: bool = True
    ) -> List[Dict]:
        """ç¬¬äºŒçº§ï¼šæ ¸å¿ƒç­›é€‰ï¼ˆè¶‹åŠ¿æ€§é‡åŒ–æŒ‡æ ‡ï¼‰

        Args:
            etf_codes: é€šè¿‡ç¬¬ä¸€çº§ç­›é€‰çš„ETFä»£ç åˆ—è¡¨
            start_date: å›æµ‹å¼€å§‹æ—¥æœŸ
            end_date: å›æµ‹ç»“æŸæ—¥æœŸ
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

        Returns:
            æŒ‰æ”¶ç›Šå›æ’¤æ¯”æ’åºçš„ETFä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
            - ts_code, name, industry
            - adx_mean, return_dd_ratio, volatility, momentum_3m, momentum_12m
        """
        use_ma_filter = self.config.enable_ma_backtest_filter

        if verbose:
            print("ğŸ§® ç¬¬äºŒçº§ç­›é€‰ï¼šè¶‹åŠ¿æ€§é‡åŒ–åˆ†æ")
            print(f"  ğŸ“Š å¾…åˆ†æETFæ•°é‡: {len(etf_codes)}")

        metrics_list = []
        basic_info = self.data_loader.load_basic_info(fund_type=None)  # åŠ è½½å…¨éƒ¨ä»¥è·å–åç§°

        for i, ts_code in enumerate(etf_codes):
            if verbose and (i + 1) % 100 == 0:
                print(f"  ğŸƒ è¿›åº¦: {i + 1}/{len(etf_codes)}")

            try:
                # åŠ è½½æ•°æ®
                data = self.data_loader.load_etf_daily(
                    ts_code, start_date=start_date, end_date=end_date, use_adj=True
                )

                # æ•°æ®é•¿åº¦æ£€æŸ¥ï¼ˆéœ€è¦è¶³å¤Ÿçš„æ•°æ®è®¡ç®—æŒ‡æ ‡ï¼‰
                min_data_length = max(
                    self.config.ma_long + 10,  # åŒå‡çº¿éœ€è¦çš„æœ€å°é•¿åº¦
                    self.config.adx_period + self.config.adx_lookback_days // 4,  # ADXéœ€è¦çš„æœ€å°é•¿åº¦
                    100  # è‡³å°‘100å¤©
                )

                if len(data) < min_data_length:
                    continue

                # 1. ADXè¶‹åŠ¿å¼ºåº¦
                adx_mean = calculate_rolling_adx_mean(
                    data['adj_high'], data['adj_low'], data['adj_close'],
                    adx_period=self.config.adx_period,
                    window=min(self.config.adx_lookback_days, len(data))
                )

                if np.isnan(adx_mean):
                    continue

                if use_ma_filter:
                    # 2. åŒå‡çº¿å›æµ‹
                    backtest_metrics = calculate_backtest_metrics(
                        data, short=self.config.ma_short, long=self.config.ma_long, use_adj=True
                    )

                    annual_return = backtest_metrics['annual_return']
                    max_drawdown = backtest_metrics['max_drawdown']
                    return_dd_ratio = backtest_metrics['return_dd_ratio']
                else:
                    annual_return = np.nan
                    max_drawdown = np.nan
                    return_dd_ratio = np.nan

                # 3. æ³¢åŠ¨ç‡
                returns = data['adj_close'].pct_change().dropna()
                volatility = calculate_volatility(
                    returns, window=min(self.config.volatility_lookback_days, len(returns))
                )

                if np.isnan(volatility):
                    continue

                # 4. åŠ¨é‡
                momentum_periods = self.config.momentum_periods or [63, 252]
                momentum = calculate_momentum(data['adj_close'], periods=momentum_periods)
                momentum_3m = momentum.get('63d', np.nan)
                momentum_12m = momentum.get('252d', np.nan)

                # åº”ç”¨ç­›é€‰æ¡ä»¶
                # æ³¢åŠ¨ç‡èŒƒå›´æ£€æŸ¥
                if volatility < self.config.min_volatility or volatility > self.config.max_volatility:
                    continue

                # åŠ¨é‡æ£€æŸ¥ï¼ˆ3ä¸ªæœˆåŠ¨é‡å¿…é¡»ä¸ºæ­£ï¼‰
                if np.isnan(momentum_3m) or momentum_3m <= 0:
                    continue

                # è·å–ETFåç§°å’Œè¡Œä¸šåˆ†ç±»
                etf_info = basic_info[basic_info['ts_code'] == ts_code]
                name = etf_info['name'].iloc[0] if len(etf_info) > 0 else ts_code
                industry = self.industry_classifier.classify(name)

                # å­˜å‚¨æŒ‡æ ‡
                metrics_list.append({
                    'ts_code': ts_code,
                    'name': name,
                    'industry': industry,
                    'adx_mean': adx_mean,
                    'annual_return': annual_return,
                    'max_drawdown': max_drawdown,
                    'return_dd_ratio': return_dd_ratio,
                    'volatility': volatility,
                    'momentum_3m': momentum_3m,
                    'momentum_12m': momentum_12m,
                })

            except Exception as e:
                if verbose and isinstance(e, (FileNotFoundError, ValueError)):
                    # è¿™äº›æ˜¯é¢„æœŸçš„é”™è¯¯ï¼Œä¸éœ€è¦æ‰“å°å †æ ˆ
                    pass
                else:
                    warnings.warn(f"å¤„ç† {ts_code} æ—¶å‡ºé”™: {e}")
                continue

        if verbose:
            print(f"  âœ… è®¡ç®—å®Œæˆï¼Œè·å¾— {len(metrics_list)} åªæœ‰æ•ˆæ ‡çš„")

        if len(metrics_list) == 0:
            return []

        # è½¬ä¸ºDataFrameä¾¿äºæ’åºå’Œç­›é€‰
        df = pd.DataFrame(metrics_list)

        # ADXç­›é€‰ï¼šä¿ç•™å‰adx_percentile%çš„æ ‡çš„
        adx_threshold = np.percentile(df['adx_mean'], self.config.adx_percentile)
        df = df[df['adx_mean'] >= adx_threshold]

        if verbose:
            print(f"  ğŸ¯ ADXç­›é€‰(>{adx_threshold:.1f}): ä¿ç•™ {len(df)} åª")

        # æ”¶ç›Šå›æ’¤æ¯”ç­›é€‰ï¼šä¿ç•™å‰ret_dd_percentile%çš„æ ‡çš„ï¼ˆå¯é€‰ï¼‰
        if len(df) > 0 and use_ma_filter:
            ret_dd_threshold = np.percentile(df['return_dd_ratio'], self.config.ret_dd_percentile)
            df = df[df['return_dd_ratio'] >= ret_dd_threshold]

            if verbose:
                print(f"  ğŸ“ˆ æ”¶ç›Šå›æ’¤æ¯”ç­›é€‰(>{ret_dd_threshold:.2f}): ä¿ç•™ {len(df)} åª")
        elif len(df) > 0 and not use_ma_filter and verbose:
            print("  âš ï¸ å·²ç¦ç”¨åŒå‡çº¿å›æµ‹è¿‡æ»¤ï¼Œè·³è¿‡æ”¶ç›Šå›æ’¤æ¯”ç­›é€‰")

        # æŒ‰æ”¶ç›Šå›æ’¤æ¯”é™åºæ’åº
        if use_ma_filter:
            df = df.sort_values('return_dd_ratio', ascending=False).reset_index(drop=True)
        else:
            sort_columns = ['adx_mean', 'momentum_12m', 'momentum_3m']
            df = df.sort_values(
                by=sort_columns, ascending=[False, False, False], na_position='last'
            ).reset_index(drop=True)

        # æ·»åŠ æ’åä¿¡æ¯
        df['stage2_rank'] = range(1, len(df) + 1)

        if verbose:
            print(f"  ğŸ† ç¬¬äºŒçº§ç­›é€‰å®Œæˆï¼Œå…± {len(df)} åªæ ‡çš„é€šè¿‡")
            if len(df) > 0:
                print(f"  ğŸ“Š ADXå‡å€¼èŒƒå›´: {df['adx_mean'].min():.1f} ~ {df['adx_mean'].max():.1f}")
                print(f"  ğŸ“Š æ³¢åŠ¨ç‡èŒƒå›´: {df['volatility'].min():.1%} ~ {df['volatility'].max():.1%}")
                if use_ma_filter:
                    print(
                        f"  ğŸ“Š æ”¶ç›Šå›æ’¤æ¯”èŒƒå›´: "
                        f"{df['return_dd_ratio'].min():.2f} ~ {df['return_dd_ratio'].max():.2f}"
                    )
                else:
                    print("  ğŸ“Š å·²ç¦ç”¨æ”¶ç›Šå›æ’¤æ¯”æ’åï¼Œç»“æœæŒ‰ADX+åŠ¨é‡æ’åº")

        return df.to_dict('records')

    def export_results(
        self,
        results: List[Dict],
        output_path: str,
        stage: str = 'final'
    ) -> None:
        """å¯¼å‡ºç­›é€‰ç»“æœåˆ°CSVæ–‡ä»¶

        Args:
            results: ç­›é€‰ç»“æœåˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            stage: ç­›é€‰é˜¶æ®µæ ‡è¯†ï¼ˆç”¨äºæ–‡ä»¶åï¼‰
        """
        if len(results) == 0:
            print(f"âŒ æ— ç»“æœå¯å¯¼å‡º")
            return

        df = pd.DataFrame(results)

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # å¯¼å‡ºCSVï¼ˆç›´æ¥ä½¿ç”¨æŒ‡å®šçš„è·¯å¾„ï¼Œä¸æ·»åŠ æ—¶é—´æˆ³ï¼‰
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"âœ… ç»“æœå·²å¯¼å‡º: {output_path} ({len(df)} åªETF)")

    def get_summary_stats(self) -> Dict:
        """è·å–ç­›é€‰ç»Ÿè®¡æ‘˜è¦

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        stats = {}

        for stage, results in self.stage_results.items():
            if isinstance(results, list):
                if len(results) > 0 and isinstance(results[0], dict):
                    # ç¬¬äºŒçº§åŠä»¥åçš„ç»“æœ
                    df = pd.DataFrame(results)
                    stats[stage] = {
                        'count': len(df),
                        'avg_return_dd_ratio': df['return_dd_ratio'].mean() if 'return_dd_ratio' in df.columns else None,
                        'avg_adx': df['adx_mean'].mean() if 'adx_mean' in df.columns else None,
                        'avg_volatility': df['volatility'].mean() if 'volatility' in df.columns else None,
                    }
                else:
                    # ç¬¬ä¸€çº§ç»“æœï¼ˆåªæœ‰ä»£ç åˆ—è¡¨ï¼‰
                    stats[stage] = {'count': len(results)}

        return stats

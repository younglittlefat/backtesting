#!/usr/bin/env python3
"""
è½®åŠ¨è¡¨ç”Ÿæˆè„šæœ¬

ä¸ºåŠ¨æ€æ± å­è½®åŠ¨ç­–ç•¥ç”Ÿæˆæ—¶é—´åºåˆ—è½®åŠ¨è¡¨ã€‚åœ¨æ¯ä¸ªè½®åŠ¨æ—¥æœŸï¼Œä½¿ç”¨å†å²æ•°æ®é‡æ–°ç­›é€‰ETFæ± ï¼Œ
ç”ŸæˆJSONæ ¼å¼çš„è½®åŠ¨æ—¶é—´è¡¨ä¾›åç»­å›æµ‹ä½¿ç”¨ã€‚

å…³é”®ç‰¹æ€§ï¼š
1. é¿å…æœªæ¥æ•°æ®æ³„éœ²ï¼šè¯„åˆ†çª—å£ä¸¥æ ¼é™åˆ¶åœ¨[T-lookback, T-1]
2. æ”¯æŒå¤šç§è½®åŠ¨å‘¨æœŸï¼ˆ7/15/30/60å¤©ï¼‰
3. è¾“å‡ºå®Œæ•´ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ¢æ‰‹ç‡ã€æ± å­ç¨³å®šæ€§ç­‰ï¼‰

ä½¿ç”¨ç¤ºä¾‹ï¼š
    python scripts/prepare_rotation_schedule.py \\
        --start-date 2023-11-01 \\
        --end-date 2025-11-12 \\
        --rotation-period 30 \\
        --pool-size 20 \\
        --output results/rotation_schedules/rotation_30d.json
"""

import argparse
import json
import sys
from collections import Counter
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple

import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from etf_selector.config import FilterConfig
from etf_selector.data_loader import ETFDataLoader
from etf_selector.selector import TrendETFSelector


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='ç”ŸæˆåŠ¨æ€æ± å­è½®åŠ¨æ—¶é—´è¡¨',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    # å¿…éœ€å‚æ•°
    parser.add_argument(
        '--start-date', type=str, required=True,
        help='è½®åŠ¨å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)ï¼Œå¦‚ 2023-11-01'
    )
    parser.add_argument(
        '--end-date', type=str, required=True,
        help='è½®åŠ¨ç»“æŸæ—¥æœŸ (YYYY-MM-DD)ï¼Œå¦‚ 2025-11-12'
    )
    parser.add_argument(
        '--rotation-period', type=int, required=True,
        help='è½®åŠ¨å‘¨æœŸï¼ˆå¤©ï¼‰ï¼Œå¦‚ 7/15/30/60'
    )

    # å¯é€‰å‚æ•°
    parser.add_argument(
        '--pool-size', type=int, default=20,
        help='æ¯æ¬¡ç­›é€‰çš„ETFæ•°é‡ (é»˜è®¤: 20)'
    )
    parser.add_argument(
        '--lookback-days', type=int, default=120,
        help='è¯„åˆ†çª—å£å¤©æ•° (é»˜è®¤: 120å¤©)'
    )
    parser.add_argument(
        '--data-dir', type=str, default='data/chinese_etf',
        help='ETFæ•°æ®æ ¹ç›®å½•è·¯å¾„ (é»˜è®¤: data/chinese_etf)'
    )
    parser.add_argument(
        '--output', type=str,
        help='è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º results/rotation_schedules/rotation_{period}d.json'
    )
    parser.add_argument(
        '--verbose', action='store_true', default=True,
        help='æ˜¾ç¤ºè¯¦ç»†è¿›åº¦ä¿¡æ¯'
    )
    parser.add_argument(
        '--quiet', action='store_true',
        help='é™é»˜æ¨¡å¼ï¼Œä»…æ˜¾ç¤ºå…³é”®ä¿¡æ¯'
    )
    parser.add_argument(
        '--no-score-threshold', action='store_true', default=True,
        help='è·³è¿‡äºŒé˜¶æ®µç™¾åˆ†ä½è¿‡æ»¤ï¼Œæ”¹ä¸ºçº¯è¯„åˆ†æ’åºå–top-N (é»˜è®¤: True)'
    )
    parser.add_argument(
        '--use-score-threshold', dest='no_score_threshold', action='store_false',
        help='å¯ç”¨äºŒé˜¶æ®µç™¾åˆ†ä½è¿‡æ»¤ï¼ˆä¸é»˜è®¤è¡Œä¸ºç›¸åï¼‰'
    )

    return parser.parse_args()


def calculate_rotation_dates(
    start_date: str,
    end_date: str,
    rotation_period: int
) -> List[str]:
    """è®¡ç®—è½®åŠ¨æ—¥æœŸåºåˆ—

    Args:
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        rotation_period: è½®åŠ¨å‘¨æœŸï¼ˆå¤©ï¼‰

    Returns:
        æ—¥æœŸå­—ç¬¦ä¸²åˆ—è¡¨ (YYYY-MM-DDæ ¼å¼)
    """
    start = datetime.strptime(start_date, '%Y-%m-%d')
    end = datetime.strptime(end_date, '%Y-%m-%d')

    rotation_dates = []
    current = start

    while current <= end:
        rotation_dates.append(current.strftime('%Y-%m-%d'))
        current += timedelta(days=rotation_period)

    return rotation_dates


def select_etfs_for_date(
    selector: TrendETFSelector,
    rotation_date: str,
    lookback_days: int,
    pool_size: int,
    verbose: bool = False
) -> Tuple[List[str], Dict]:
    """ä¸ºæŒ‡å®šæ—¥æœŸç­›é€‰ETFæ± 

    å…³é”®ç‚¹ï¼šä½¿ç”¨æˆªæ­¢åˆ°rotation_date-1çš„å…¨éƒ¨å†å²æ•°æ®è¿›è¡Œè¯„åˆ†
    ï¼ˆä¸é™åˆ¶120å¤©çª—å£ï¼Œå› ä¸ºçŸ­çª—å£ä¼šå¯¼è‡´æµåŠ¨æ€§ç­‰æŒ‡æ ‡è®¡ç®—å¤±è´¥ï¼‰

    Args:
        selector: ETFç­›é€‰å™¨å®ä¾‹
        rotation_date: è½®åŠ¨æ—¥æœŸ (YYYY-MM-DD)
        lookback_days: è¯„åˆ†çª—å£å¤©æ•°ï¼ˆå·²å¼ƒç”¨ï¼Œä¿ç•™å‚æ•°å…¼å®¹æ€§ï¼‰
        pool_size: ç›®æ ‡æ± å­å¤§å°
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        (etf_codes, metadata): ETFä»£ç åˆ—è¡¨å’Œå…ƒæ•°æ®å­—å…¸
    """
    rot_date = datetime.strptime(rotation_date, '%Y-%m-%d')

    # ä½¿ç”¨æˆªæ­¢åˆ°è½®åŠ¨æ—¥æœŸå‰ä¸€å¤©çš„å…¨éƒ¨å†å²æ•°æ®ï¼ˆä¸é™åˆ¶çª—å£ï¼‰
    end_date_str = (rot_date - timedelta(days=1)).strftime('%Y-%m-%d')

    if verbose:
        print(f"  ğŸ“Š è¯„åˆ†çª—å£: å…¨éƒ¨å†å²æ•°æ® è‡³ {end_date_str}")

    # æ‰§è¡Œç­›é€‰ï¼ˆé™é»˜æ¨¡å¼ï¼‰
    try:
        selected_etfs = selector.run_pipeline(
            start_date=None,  # Noneè¡¨ç¤ºä½¿ç”¨å…¨éƒ¨å†å²æ•°æ®
            end_date=end_date_str,
            target_size=pool_size,
            verbose=True  # ä¸´æ—¶å¯ç”¨è¯¦ç»†æ—¥å¿—ï¼Œç”¨äºè°ƒè¯•
        )

        # æå–ä»£ç åˆ—è¡¨
        etf_codes = [etf['ts_code'] for etf in selected_etfs]

        # æ”¶é›†å…ƒæ•°æ®
        metadata = {
            'count': len(etf_codes),
            'score_window_start': 'all_history',
            'score_window_end': end_date_str,
            'top_3_etfs': etf_codes[:3] if len(etf_codes) >= 3 else etf_codes
        }

        return etf_codes, metadata

    except Exception as e:
        if verbose:
            print(f"  âŒ ç­›é€‰å¤±è´¥: {e}")
        return [], {'count': 0, 'error': str(e)}


def calculate_turnover_rate(old_pool: List[str], new_pool: List[str]) -> float:
    """è®¡ç®—æ¢æ‰‹ç‡

    å®šä¹‰ï¼š(å–å‡ºæ•°é‡ + ä¹°å…¥æ•°é‡) / (2 * æ± å­å¤§å°)

    Args:
        old_pool: æ—§æ± å­ä»£ç åˆ—è¡¨
        new_pool: æ–°æ± å­ä»£ç åˆ—è¡¨

    Returns:
        æ¢æ‰‹ç‡ï¼ˆ0-1ä¹‹é—´ï¼‰
    """
    if not old_pool or not new_pool:
        return 0.0

    old_set = set(old_pool)
    new_set = set(new_pool)

    n_sell = len(old_set - new_set)  # è¢«æ·˜æ±°çš„
    n_buy = len(new_set - old_set)   # æ–°å¢çš„

    pool_size = len(old_pool)
    turnover = (n_sell + n_buy) / (2 * pool_size)

    return turnover


def calculate_statistics(
    schedule: Dict[str, List[str]]
) -> Dict:
    """è®¡ç®—è½®åŠ¨ç»Ÿè®¡ä¿¡æ¯

    Args:
        schedule: è½®åŠ¨æ—¶é—´è¡¨ {date: [codes]}

    Returns:
        ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    dates = sorted(schedule.keys())

    if len(dates) < 2:
        return {
            'total_rotations': len(dates),
            'avg_turnover_rate': 0.0,
            'median_overlap': 0,
            'most_stable_etfs': [],
            'most_volatile_etfs': []
        }

    # è®¡ç®—æ¢æ‰‹ç‡åºåˆ—
    turnover_rates = []
    overlap_counts = []

    for i in range(1, len(dates)):
        old_pool = schedule[dates[i-1]]
        new_pool = schedule[dates[i]]

        turnover = calculate_turnover_rate(old_pool, new_pool)
        turnover_rates.append(turnover)

        overlap = len(set(old_pool) & set(new_pool))
        overlap_counts.append(overlap)

    # ç»Ÿè®¡æ¯ä¸ªETFå‡ºç°æ¬¡æ•°
    all_etfs = []
    for codes in schedule.values():
        all_etfs.extend(codes)

    etf_counter = Counter(all_etfs)
    total_rotations = len(dates)

    # æœ€ç¨³å®šçš„ETFï¼ˆå‡ºç°æ¬¡æ•°æœ€å¤šï¼‰
    most_stable = [
        {'code': code, 'appearances': count, 'stability': count / total_rotations}
        for code, count in etf_counter.most_common(5)
    ]

    # æœ€ä¸ç¨³å®šçš„ETFï¼ˆåªå‡ºç°1æ¬¡ï¼‰
    least_stable = [
        {'code': code, 'appearances': count}
        for code, count in etf_counter.items()
        if count == 1
    ]

    return {
        'total_rotations': total_rotations,
        'avg_turnover_rate': float(sum(turnover_rates) / len(turnover_rates)),
        'min_turnover_rate': float(min(turnover_rates)),
        'max_turnover_rate': float(max(turnover_rates)),
        'median_overlap': int(sorted(overlap_counts)[len(overlap_counts) // 2]),
        'avg_overlap': float(sum(overlap_counts) / len(overlap_counts)),
        'unique_etfs_count': len(etf_counter),
        'most_stable_etfs': most_stable,
        'least_stable_count': len(least_stable),
        'turnover_trend': {
            'first_3_avg': float(sum(turnover_rates[:3]) / min(3, len(turnover_rates))),
            'last_3_avg': float(sum(turnover_rates[-3:]) / min(3, len(turnover_rates)))
        }
    }


def print_summary(
    schedule: Dict[str, List[str]],
    statistics: Dict,
    output_path: Path
):
    """æ‰“å°è½®åŠ¨è¡¨æ‘˜è¦

    Args:
        schedule: è½®åŠ¨æ—¶é—´è¡¨
        statistics: ç»Ÿè®¡ä¿¡æ¯
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    print("\n" + "=" * 80)
    print("ğŸ‰ è½®åŠ¨è¡¨ç”Ÿæˆå®Œæˆï¼")
    print("=" * 80)

    print(f"\nğŸ“Š åŸºæœ¬ä¿¡æ¯:")
    print(f"  è½®åŠ¨å‘¨æœŸæ•°: {statistics['total_rotations']} æ¬¡")
    print(f"  æ¯æ¬¡æ± å­å¤§å°: {len(next(iter(schedule.values())))} åª")
    print(f"  æ¶‰åŠETFæ€»æ•°: {statistics['unique_etfs_count']} åª")
    print(f"  è¾“å‡ºæ–‡ä»¶: {output_path}")

    print(f"\nğŸ”„ æ¢æ‰‹ç‡ç»Ÿè®¡:")
    print(f"  å¹³å‡æ¢æ‰‹ç‡: {statistics['avg_turnover_rate']:.2%}")
    print(f"  æ¢æ‰‹ç‡èŒƒå›´: {statistics['min_turnover_rate']:.2%} - {statistics['max_turnover_rate']:.2%}")
    print(f"  å¹³å‡ä¿ç•™æ•°é‡: {statistics['avg_overlap']:.1f} åª ({statistics['avg_overlap']/20*100:.0f}%)")
    print(f"  ä¸­ä½ä¿ç•™æ•°é‡: {statistics['median_overlap']} åª")

    print(f"\nâ­ æœ€ç¨³å®šçš„5åªETF (å‡ºç°é¢‘ç‡æœ€é«˜):")
    for i, etf in enumerate(statistics['most_stable_etfs'][:5]):
        print(f"  {i+1}. {etf['code']}: {etf['appearances']}/{statistics['total_rotations']} æ¬¡ ({etf['stability']:.0%})")

    print(f"\nğŸ“ˆ æ¢æ‰‹ç‡è¶‹åŠ¿:")
    print(f"  å‰3æ¬¡å¹³å‡: {statistics['turnover_trend']['first_3_avg']:.2%}")
    print(f"  å3æ¬¡å¹³å‡: {statistics['turnover_trend']['last_3_avg']:.2%}")

    trend_direction = "ä¸Šå‡" if statistics['turnover_trend']['last_3_avg'] > statistics['turnover_trend']['first_3_avg'] else "ä¸‹é™"
    print(f"  è¶‹åŠ¿: {trend_direction}")

    print(f"\nğŸ“… é¦–å°¾è½®åŠ¨æ—¥æœŸ:")
    dates = sorted(schedule.keys())
    print(f"  é¦–æ¬¡è½®åŠ¨: {dates[0]}")
    print(f"  æœ«æ¬¡è½®åŠ¨: {dates[-1]}")

    # æ˜¾ç¤ºé¦–æ¬¡å’Œæœ«æ¬¡çš„Top 3
    print(f"\nğŸ† é¦–æ¬¡è½®åŠ¨Top 3: {', '.join(schedule[dates[0]][:3])}")
    print(f"ğŸ† æœ«æ¬¡è½®åŠ¨Top 3: {', '.join(schedule[dates[-1]][:3])}")

    print("\n" + "=" * 80)


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    verbose = args.verbose and not args.quiet

    if verbose:
        print("=" * 80)
        print(" è½®åŠ¨è¡¨ç”Ÿæˆå™¨ - åŠ¨æ€æ± å­è½®åŠ¨ç­–ç•¥")
        print("=" * 80)
        print(f"\nâš™ï¸  é…ç½®å‚æ•°:")
        print(f"  è½®åŠ¨å‘¨æœŸ: {args.rotation_period} å¤©")
        print(f"  æ± å­å¤§å°: {args.pool_size} åª")
        print(f"  è¯„åˆ†çª—å£: {args.lookback_days} å¤©")
        print(f"  å›æµ‹åŒºé—´: {args.start_date} è‡³ {args.end_date}")
        print(f"  æ•°æ®æ ¹ç›®å½•: {args.data_dir}")

    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if args.output:
        output_path = Path(args.output)
    else:
        output_path = Path('results/rotation_schedules') / f'rotation_{args.rotation_period}d.json'

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # åˆå§‹åŒ–ETFç­›é€‰å™¨
    try:
        if verbose:
            print("\nğŸš€ åˆå§‹åŒ–ETFç­›é€‰å™¨...")

        config = FilterConfig()
        config.target_portfolio_size = args.pool_size
        # æ”¾å®½æµåŠ¨æ€§é˜ˆå€¼ï¼Œé€‚åº”Aè‚¡ETFå¸‚åœºç‰¹ç‚¹å’ŒçŸ­æœŸå†å²çª—å£
        config.min_turnover = 50_000  # 5ä¸‡å…ƒï¼ŒåŸé»˜è®¤1äº¿
        # æ”¾å®½å…¶ä»–é™åˆ¶ï¼Œç¡®ä¿çŸ­çª—å£ä¸‹èƒ½ç­›é€‰å‡ºè¶³å¤ŸETF
        config.min_listing_days = 60  # åŸé»˜è®¤180å¤©ï¼Œé™ä½åˆ°60å¤©
        # â­ è·³è¿‡ç¬¬äºŒçº§çš„ç™¾åˆ†ä½ç­›é€‰å’ŒèŒƒå›´è¿‡æ»¤ï¼Œç›´æ¥æŒ‰ç»¼åˆè¯„åˆ†æ’åºï¼ˆå¯é€šè¿‡å‘½ä»¤è¡Œæ§åˆ¶ï¼‰
        config.skip_stage2_percentile_filtering = args.no_score_threshold
        config.skip_stage2_range_filtering = args.no_score_threshold
        # å¯ç”¨æ— åè¯„åˆ†ï¼ˆé¿å…åŠ¨é‡åå·®ï¼‰
        config.enable_unbiased_scoring = True

        data_loader = ETFDataLoader(args.data_dir)
        selector = TrendETFSelector(config=config, data_loader=data_loader)

        if verbose:
            print("âœ… ç­›é€‰å™¨åˆå§‹åŒ–å®Œæˆ")

    except Exception as e:
        print(f"âŒ ç­›é€‰å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return 1

    # è®¡ç®—è½®åŠ¨æ—¥æœŸåºåˆ—
    rotation_dates = calculate_rotation_dates(
        args.start_date,
        args.end_date,
        args.rotation_period
    )

    if verbose:
        print(f"\nğŸ“… ç”Ÿæˆè½®åŠ¨æ—¥æœŸåºåˆ—:")
        print(f"  å…± {len(rotation_dates)} ä¸ªè½®åŠ¨ç‚¹")
        print(f"  é¦–æ¬¡: {rotation_dates[0]}")
        print(f"  æœ«æ¬¡: {rotation_dates[-1]}")

    # é€æ—¥ç­›é€‰ETFæ± 
    schedule = {}
    metadata_log = {}

    if verbose:
        print(f"\nğŸ” å¼€å§‹é€æ—¥ç­›é€‰ETFæ± ...")
        print("-" * 80)

    for i, rot_date in enumerate(rotation_dates):
        if verbose:
            print(f"\n[{i+1}/{len(rotation_dates)}] å¤„ç† {rot_date}:")

        etf_codes, metadata = select_etfs_for_date(
            selector=selector,
            rotation_date=rot_date,
            lookback_days=args.lookback_days,
            pool_size=args.pool_size,
            verbose=verbose
        )

        if len(etf_codes) == 0:
            print(f"  âš ï¸  è­¦å‘Š: {rot_date} ç­›é€‰ç»“æœä¸ºç©ºï¼Œè·³è¿‡")
            continue

        schedule[rot_date] = etf_codes
        metadata_log[rot_date] = metadata

        if verbose:
            print(f"  âœ… ç­›é€‰å®Œæˆ: {len(etf_codes)} åª")
            print(f"  Top 3: {', '.join(etf_codes[:3])}")

            # è®¡ç®—ä¸ä¸Šä¸€æœŸçš„å˜åŒ–ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if i > 0 and len(schedule) >= 2:
                prev_date = rotation_dates[i-1]
                if prev_date in schedule:
                    turnover = calculate_turnover_rate(schedule[prev_date], etf_codes)
                    overlap = len(set(schedule[prev_date]) & set(etf_codes))
                    print(f"  ğŸ”„ æ¢æ‰‹ç‡: {turnover:.2%} (ä¿ç•™ {overlap} åª)")

    if len(schedule) == 0:
        print("âŒ è½®åŠ¨è¡¨ç”Ÿæˆå¤±è´¥ï¼šæ‰€æœ‰æ—¥æœŸç­›é€‰ç»“æœå‡ä¸ºç©º")
        return 1

    if verbose:
        print("\n" + "-" * 80)
        print("âœ… æ‰€æœ‰æ—¥æœŸç­›é€‰å®Œæˆ")

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    statistics = calculate_statistics(schedule)

    # æ„å»ºè¾“å‡ºJSON
    output_data = {
        'metadata': {
            'rotation_period': args.rotation_period,
            'pool_size': args.pool_size,
            'lookback_days': args.lookback_days,
            'start_date': args.start_date,
            'end_date': args.end_date,
            'total_rotations': len(schedule),
            'data_dir': args.data_dir,
            'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        },
        'schedule': schedule,
        'statistics': statistics,
        'metadata_log': metadata_log
    }

    # ä¿å­˜JSONæ–‡ä»¶
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)

        if verbose:
            print(f"\nğŸ’¾ è½®åŠ¨è¡¨å·²ä¿å­˜: {output_path}")

    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        return 1

    # æ‰“å°æ‘˜è¦
    if verbose:
        print_summary(schedule, statistics, output_path)

    return 0


if __name__ == "__main__":
    sys.exit(main())

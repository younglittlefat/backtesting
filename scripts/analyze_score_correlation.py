#!/usr/bin/env python3
"""
Score æ­£äº¤æ£€éªŒåˆ†æè„šæœ¬

è®¡ç®—å„ä¸ª score ä¹‹é—´çš„ç›¸å…³æ€§çŸ©é˜µå’Œæ± å­é‡å åº¦ï¼Œç”¨äºæŒ‡å¯¼ score ç»„åˆæƒé‡è®¾è®¡ã€‚

ä½¿ç”¨æ–¹æ³•:
    # å•æ–‡ä»¶åˆ†æ
    python scripts/analyze_score_correlation.py path/to/all_scores.csv

    # å¤šæ–‡ä»¶æ± å­é‡å åº¦åˆ†æï¼ˆè‹±æ–‡é€—å·åˆ†éš”ï¼‰
    python scripts/analyze_score_correlation.py pool1.csv,pool2.csv,pool3.csv

    # æŒ‡å®šè¾“å‡ºç›®å½•
    python scripts/analyze_score_correlation.py all_scores.csv --output-dir results/correlation

è¾“å‡º:
    - correlation_matrix.csv: ç›¸å…³æ€§çŸ©é˜µ
    - correlation_heatmap.png: çƒ­åŠ›å›¾å¯è§†åŒ–
    - jaccard_similarity.csv: æ± å­é‡å åº¦ï¼ˆå¤šæ–‡ä»¶æ—¶ï¼‰
    - analysis_report.txt: åˆ†ææŠ¥å‘Šå’Œå»ºè®®
"""
import argparse
import sys
from pathlib import Path

import numpy as np
import pandas as pd


def load_score_data(file_path: str) -> pd.DataFrame:
    """åŠ è½½ score æ•°æ®æ–‡ä»¶"""
    df = pd.read_csv(file_path)
    return df


def calculate_correlation_matrix(
    df: pd.DataFrame,
    score_columns: list = None,
    method: str = 'spearman'
) -> pd.DataFrame:
    """
    è®¡ç®— score ç›¸å…³æ€§çŸ©é˜µ

    Args:
        df: åŒ…å« score æ•°æ®çš„ DataFrame
        score_columns: è¦è®¡ç®—ç›¸å…³æ€§çš„åˆ—ååˆ—è¡¨ï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹
        method: ç›¸å…³æ€§è®¡ç®—æ–¹æ³•ï¼Œ'spearman'ï¼ˆæ¨èï¼‰æˆ– 'pearson'

    Returns:
        ç›¸å…³æ€§çŸ©é˜µ DataFrame
    """
    # é»˜è®¤çš„ score åˆ—ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åˆ—ï¼‰
    default_score_columns = [
        # æ ¸å¿ƒ 4 ä¸ªå• score
        'adx_mean', 'trend_consistency', 'price_efficiency', 'liquidity_score',
        # åŠ¨é‡
        'momentum_3m', 'momentum_12m',
        # æ–°ç‰ˆè¯„åˆ†è¾“å…¥
        'excess_return_20d', 'excess_return_60d', 'trend_quality', 'volume_trend', 'idr',
    ]

    if score_columns is None:
        # è‡ªåŠ¨æ£€æµ‹å­˜åœ¨çš„åˆ—
        score_columns = [col for col in default_score_columns if col in df.columns]

    if len(score_columns) < 2:
        raise ValueError(f"è‡³å°‘éœ€è¦2ä¸ª score åˆ—è¿›è¡Œç›¸å…³æ€§åˆ†æï¼Œå½“å‰åªæœ‰: {score_columns}")

    # æå– score æ•°æ®
    df_scores = df[score_columns].copy()

    # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ï¼ˆå¤„ç†å¯èƒ½çš„å­—ç¬¦ä¸²ï¼‰
    for col in score_columns:
        df_scores[col] = pd.to_numeric(df_scores[col], errors='coerce')

    # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
    corr_matrix = df_scores.corr(method=method)

    return corr_matrix


def calculate_jaccard_similarity(pools: dict) -> pd.DataFrame:
    """
    è®¡ç®—å¤šä¸ªæ± å­ä¹‹é—´çš„ Jaccard ç›¸ä¼¼åº¦

    Args:
        pools: å­—å…¸ {æ± å­åç§°: set(ts_code)}

    Returns:
        Jaccard ç›¸ä¼¼åº¦çŸ©é˜µ DataFrame
    """
    pool_names = list(pools.keys())
    n = len(pool_names)

    jaccard_matrix = pd.DataFrame(
        np.zeros((n, n)),
        index=pool_names,
        columns=pool_names
    )

    for i, name1 in enumerate(pool_names):
        for j, name2 in enumerate(pool_names):
            set1 = pools[name1]
            set2 = pools[name2]
            if len(set1 | set2) > 0:
                jaccard = len(set1 & set2) / len(set1 | set2)
            else:
                jaccard = 0.0
            jaccard_matrix.loc[name1, name2] = jaccard

    return jaccard_matrix


def interpret_correlation(corr_value: float) -> str:
    """è§£è¯»ç›¸å…³ç³»æ•°"""
    abs_corr = abs(corr_value)
    if abs_corr < 0.3:
        return "æ­£äº¤/ç‹¬ç«‹ âœ…"
    elif abs_corr < 0.6:
        return "ä¸­åº¦ç›¸å…³ âš ï¸"
    else:
        return "é«˜åº¦ç›¸å…³ âŒ"


def generate_report(
    corr_matrix: pd.DataFrame,
    jaccard_matrix: pd.DataFrame = None,
    output_path: Path = None
) -> str:
    """
    ç”Ÿæˆåˆ†ææŠ¥å‘Š

    Args:
        corr_matrix: ç›¸å…³æ€§çŸ©é˜µ
        jaccard_matrix: Jaccard ç›¸ä¼¼åº¦çŸ©é˜µï¼ˆå¯é€‰ï¼‰
        output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰

    Returns:
        æŠ¥å‘Šæ–‡æœ¬
    """
    lines = []
    lines.append("=" * 70)
    lines.append("Score æ­£äº¤æ£€éªŒåˆ†ææŠ¥å‘Š")
    lines.append("=" * 70)
    lines.append("")

    # ç›¸å…³æ€§çŸ©é˜µåˆ†æ
    lines.append("ã€1. ç›¸å…³æ€§çŸ©é˜µã€‘")
    lines.append("-" * 50)
    lines.append(corr_matrix.round(3).to_string())
    lines.append("")

    # å…³é”®å‘ç°
    lines.append("ã€2. å…³é”®å‘ç°ã€‘")
    lines.append("-" * 50)

    score_pairs = []
    columns = corr_matrix.columns.tolist()
    for i in range(len(columns)):
        for j in range(i + 1, len(columns)):
            col1, col2 = columns[i], columns[j]
            corr_value = corr_matrix.loc[col1, col2]
            if not np.isnan(corr_value):
                score_pairs.append((col1, col2, corr_value))

    # æŒ‰ç›¸å…³æ€§ç»å¯¹å€¼æ’åº
    score_pairs.sort(key=lambda x: abs(x[2]), reverse=True)

    lines.append("ç›¸å…³æ€§æ’åºï¼ˆä»é«˜åˆ°ä½ï¼‰:")
    for col1, col2, corr in score_pairs:
        interpretation = interpret_correlation(corr)
        lines.append(f"  {col1} vs {col2}: {corr:.3f} {interpretation}")

    lines.append("")

    # ç»„åˆå»ºè®®
    lines.append("ã€3. ç»„åˆå»ºè®®ã€‘")
    lines.append("-" * 50)

    # æ‰¾å‡ºæ­£äº¤çš„ç»„åˆ
    orthogonal_pairs = [(c1, c2, c) for c1, c2, c in score_pairs if abs(c) < 0.3]
    redundant_pairs = [(c1, c2, c) for c1, c2, c in score_pairs if abs(c) >= 0.6]

    if orthogonal_pairs:
        lines.append("âœ… æ¨èç»„åˆï¼ˆæ­£äº¤ï¼Œ|r| < 0.3ï¼‰:")
        for col1, col2, corr in orthogonal_pairs[:5]:
            lines.append(f"   - {col1} + {col2} (r={corr:.3f})")
    else:
        lines.append("âš ï¸ æœªå‘ç°å®Œå…¨æ­£äº¤çš„ score ç»„åˆ")

    lines.append("")

    if redundant_pairs:
        lines.append("âŒ é¿å…åŒæ—¶ä½¿ç”¨ï¼ˆé«˜åº¦ç›¸å…³ï¼Œ|r| >= 0.6ï¼‰:")
        for col1, col2, corr in redundant_pairs:
            lines.append(f"   - {col1} vs {col2} (r={corr:.3f})ï¼Œå»ºè®®äºŒé€‰ä¸€")

    lines.append("")

    # Jaccard åˆ†æï¼ˆå¦‚æœæœ‰ï¼‰
    if jaccard_matrix is not None:
        lines.append("ã€4. æ± å­é‡å åº¦åˆ†æ (Jaccard)ã€‘")
        lines.append("-" * 50)
        lines.append(jaccard_matrix.round(3).to_string())
        lines.append("")

        lines.append("é‡å åº¦è§£è¯»:")
        pool_names = jaccard_matrix.columns.tolist()
        for i in range(len(pool_names)):
            for j in range(i + 1, len(pool_names)):
                name1, name2 = pool_names[i], pool_names[j]
                jaccard = jaccard_matrix.loc[name1, name2]
                if jaccard < 0.2:
                    interp = "å‡ ä¹ä¸é‡å ï¼Œäº’è¡¥æ€§å¼º âœ…"
                elif jaccard < 0.5:
                    interp = "éƒ¨åˆ†é‡å  âš ï¸"
                else:
                    interp = "é«˜åº¦é‡å ï¼Œé€‰å‡ºç›¸ä¼¼ETF âŒ"
                lines.append(f"  {name1} vs {name2}: {jaccard:.3f} {interp}")

    lines.append("")
    lines.append("=" * 70)

    report = "\n".join(lines)

    if output_path:
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {output_path}")

    return report


def plot_heatmap(corr_matrix: pd.DataFrame, output_path: Path):
    """ç»˜åˆ¶ç›¸å…³æ€§çƒ­åŠ›å›¾"""
    try:
        import matplotlib
        matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯
        import matplotlib.pyplot as plt
        import seaborn as sns

        plt.figure(figsize=(10, 8))

        # ä½¿ç”¨ seaborn ç»˜åˆ¶çƒ­åŠ›å›¾
        sns.heatmap(
            corr_matrix,
            annot=True,
            fmt='.3f',
            cmap='RdYlGn_r',  # çº¢(é«˜ç›¸å…³)-é»„-ç»¿(ä½ç›¸å…³)
            vmin=-1,
            vmax=1,
            center=0,
            square=True,
            linewidths=0.5
        )

        plt.title('Score Correlation Matrix (Spearman)', fontsize=14)
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()

        print(f"âœ… çƒ­åŠ›å›¾å·²ä¿å­˜: {output_path}")

    except ImportError as e:
        print(f"âš ï¸ æ— æ³•ç”Ÿæˆçƒ­åŠ›å›¾ï¼Œç¼ºå°‘ä¾èµ–: {e}")
        print("   è¯·å®‰è£…: pip install matplotlib seaborn")


def main():
    parser = argparse.ArgumentParser(
        description='Score æ­£äº¤æ£€éªŒåˆ†æ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    parser.add_argument(
        'input_files',
        type=str,
        help='è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼Œå¤šä¸ªæ–‡ä»¶ç”¨è‹±æ–‡é€—å·åˆ†éš”'
    )
    parser.add_argument(
        '--output-dir', '-o',
        type=str,
        default=None,
        help='è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ç¬¬ä¸€ä¸ªè¾“å…¥æ–‡ä»¶åŒç›®å½•'
    )
    parser.add_argument(
        '--method',
        type=str,
        choices=['spearman', 'pearson'],
        default='spearman',
        help='ç›¸å…³æ€§è®¡ç®—æ–¹æ³•ï¼Œé»˜è®¤ spearman'
    )
    parser.add_argument(
        '--score-columns',
        type=str,
        default=None,
        help='è¦åˆ†æçš„ score åˆ—åï¼Œé€—å·åˆ†éš”ï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹'
    )

    args = parser.parse_args()

    # è§£æè¾“å…¥æ–‡ä»¶
    input_files = [f.strip() for f in args.input_files.split(',')]
    input_files = [f for f in input_files if f]  # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²

    if len(input_files) == 0:
        print("âŒ è¯·æä¾›è‡³å°‘ä¸€ä¸ªè¾“å…¥æ–‡ä»¶")
        return 1

    # ç¡®å®šè¾“å‡ºç›®å½•
    if args.output_dir:
        output_dir = Path(args.output_dir)
    else:
        output_dir = Path(input_files[0]).parent

    output_dir.mkdir(parents=True, exist_ok=True)

    # è§£æ score åˆ—
    score_columns = None
    if args.score_columns:
        score_columns = [c.strip() for c in args.score_columns.split(',')]

    print("=" * 60)
    print("Score æ­£äº¤æ£€éªŒåˆ†æ")
    print("=" * 60)
    print(f"è¾“å…¥æ–‡ä»¶: {input_files}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ç›¸å…³æ€§æ–¹æ³•: {args.method}")
    print()

    # æƒ…å†µ1: å•æ–‡ä»¶ - è®¡ç®— score ç›¸å…³æ€§çŸ©é˜µ
    if len(input_files) == 1:
        file_path = input_files[0]
        print(f"ğŸ“‚ åŠ è½½æ•°æ®: {file_path}")

        df = load_score_data(file_path)
        print(f"   åŠ è½½äº† {len(df)} æ¡è®°å½•")

        print(f"\nğŸ“Š è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ...")
        corr_matrix = calculate_correlation_matrix(df, score_columns, args.method)

        # ä¿å­˜ç›¸å…³æ€§çŸ©é˜µ
        corr_output = output_dir / 'correlation_matrix.csv'
        corr_matrix.to_csv(corr_output)
        print(f"âœ… ç›¸å…³æ€§çŸ©é˜µå·²ä¿å­˜: {corr_output}")

        # ç»˜åˆ¶çƒ­åŠ›å›¾
        heatmap_output = output_dir / 'correlation_heatmap.png'
        plot_heatmap(corr_matrix, heatmap_output)

        # ç”ŸæˆæŠ¥å‘Š
        report_output = output_dir / 'analysis_report.txt'
        report = generate_report(corr_matrix, output_path=report_output)
        print()
        print(report)

    # æƒ…å†µ2: å¤šæ–‡ä»¶ - è®¡ç®—æ± å­é‡å åº¦
    else:
        print(f"ğŸ“‚ åŠ è½½ {len(input_files)} ä¸ªæ± å­æ–‡ä»¶...")

        pools = {}
        all_dfs = []

        for file_path in input_files:
            file_path = Path(file_path)
            if not file_path.exists():
                print(f"   âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                continue

            df = load_score_data(str(file_path))
            pool_name = file_path.stem  # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºæ± å­åç§°

            if 'ts_code' in df.columns:
                pools[pool_name] = set(df['ts_code'].tolist())
                all_dfs.append(df)
                print(f"   âœ… {pool_name}: {len(df)} åªETF")
            else:
                print(f"   âš ï¸ {pool_name}: ç¼ºå°‘ ts_code åˆ—")

        if len(pools) < 2:
            print("âŒ è‡³å°‘éœ€è¦2ä¸ªæœ‰æ•ˆçš„æ± å­æ–‡ä»¶")
            return 1

        # è®¡ç®— Jaccard ç›¸ä¼¼åº¦
        print(f"\nğŸ“Š è®¡ç®—æ± å­é‡å åº¦ (Jaccard)...")
        jaccard_matrix = calculate_jaccard_similarity(pools)

        # ä¿å­˜ Jaccard çŸ©é˜µ
        jaccard_output = output_dir / 'jaccard_similarity.csv'
        jaccard_matrix.to_csv(jaccard_output)
        print(f"âœ… Jaccard ç›¸ä¼¼åº¦çŸ©é˜µå·²ä¿å­˜: {jaccard_output}")

        # å¦‚æœæ‰€æœ‰æ–‡ä»¶éƒ½æœ‰ score åˆ—ï¼Œä¹Ÿè®¡ç®—ç›¸å…³æ€§
        corr_matrix = None
        if all_dfs:
            # åˆå¹¶æ‰€æœ‰æ•°æ®è®¡ç®—ç›¸å…³æ€§
            combined_df = pd.concat(all_dfs, ignore_index=True)
            combined_df = combined_df.drop_duplicates(subset=['ts_code'], keep='first')

            try:
                print(f"\nğŸ“Š è®¡ç®—åˆå¹¶æ•°æ®çš„ç›¸å…³æ€§çŸ©é˜µ...")
                corr_matrix = calculate_correlation_matrix(combined_df, score_columns, args.method)

                corr_output = output_dir / 'correlation_matrix.csv'
                corr_matrix.to_csv(corr_output)
                print(f"âœ… ç›¸å…³æ€§çŸ©é˜µå·²ä¿å­˜: {corr_output}")

                heatmap_output = output_dir / 'correlation_heatmap.png'
                plot_heatmap(corr_matrix, heatmap_output)

            except ValueError as e:
                print(f"   âš ï¸ æ— æ³•è®¡ç®—ç›¸å…³æ€§: {e}")

        # ç”ŸæˆæŠ¥å‘Š
        report_output = output_dir / 'analysis_report.txt'
        report = generate_report(corr_matrix, jaccard_matrix, output_path=report_output)
        print()
        print(report)

    print()
    print("âœ… åˆ†æå®Œæˆ!")
    return 0


if __name__ == '__main__':
    sys.exit(main())

#!/usr/bin/env python3
"""
ETFç­›é€‰å™¨å•ç»´åº¦æ•ˆæœéªŒè¯ä¸»å®éªŒè„šæœ¬

æ‰§è¡Œ7ä¸ªç»´åº¦çš„ç‹¬ç«‹ç­›é€‰å’ŒKAMAç­–ç•¥å›æµ‹ï¼Œåˆ†æå„ç»´åº¦çš„å•ç‹¬è´¡çŒ®æ•ˆæœã€‚
"""

import sys
import os
import subprocess
from pathlib import Path
from typing import Dict, List, Any
import pandas as pd
import numpy as np
from datetime import datetime
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from single_dimension_selector import SingleDimensionSelector


class DimensionAnalysisExperiment:
    """å•ç»´åº¦æ•ˆæœéªŒè¯å®éªŒä¸»ç±»"""

    def __init__(self, output_dir: str = None):
        """
        åˆå§‹åŒ–å®éªŒ

        Args:
            output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„results
        """
        self.experiment_dir = Path(__file__).parent
        self.output_dir = Path(output_dir or self.experiment_dir / "results")
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # è®¾ç½®æ—¥å¿—
        self._setup_logging()

        # åˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼ˆæ•°æ®è·¯å¾„ç›¸å¯¹äºé¡¹ç›®æ ¹ï¼‰
        os.chdir(project_root)
        self.logger.info(f"Working directory: {os.getcwd()}")

        # åˆå§‹åŒ–ç­›é€‰å™¨é…ç½®
        from etf_selector.config import FilterConfig
        config = FilterConfig()
        config.data_dir = 'data/chinese_etf'  # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æ•°æ®è·¯å¾„

        # åˆå§‹åŒ–ç­›é€‰å™¨
        self.selector = SingleDimensionSelector(config)

        # å®éªŒé…ç½®
        self.target_size = 20
        self.strategy_type = 'kama_cross'
        self.data_dir = 'data/chinese_etf/daily'

        # å®éªŒæ—¶é—´æˆ³
        self.experiment_time = datetime.now().strftime("%Y%m%d_%H%M%S")

        self.logger.info("=== ETFå•ç»´åº¦æ•ˆæœéªŒè¯å®éªŒåˆå§‹åŒ– ===")
        self.logger.info(f"å®éªŒç›®å½•: {self.experiment_dir}")
        self.logger.info(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        self.logger.info(f"ç›®æ ‡æ± å­å¤§å°: {self.target_size}")

    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_file = self.output_dir / "experiment.log"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

    def run_experiment(self) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´å®éªŒæµç¨‹

        Returns:
            å®éªŒç»“æœå­—å…¸
        """
        self.logger.info("\\n=== å¼€å§‹å®Œæ•´å®éªŒæµç¨‹ ===")

        try:
            # ç¬¬ä¸€æ­¥ï¼šæ‰§è¡Œç­›é€‰
            selection_results = self.run_selection_phase()

            # ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œå›æµ‹
            backtest_results = self.run_backtest_phase(selection_results)

            # ç¬¬ä¸‰æ­¥ï¼šåˆ†æç»“æœ
            analysis_results = self.run_analysis_phase(backtest_results)

            # ç¬¬å››æ­¥ï¼šç”ŸæˆæŠ¥å‘Š
            report_path = self.generate_final_report(analysis_results)

            # æ±‡æ€»å®éªŒç»“æœ
            experiment_results = {
                'selection_results': selection_results,
                'backtest_results': backtest_results,
                'analysis_results': analysis_results,
                'report_path': report_path,
                'experiment_time': self.experiment_time,
                'success': True
            }

            self.logger.info("\\n=== å®éªŒå®Œæˆ ===")
            self.logger.info(f"å®éªŒæŠ¥å‘Š: {report_path}")

            return experiment_results

        except Exception as e:
            self.logger.error(f"å®éªŒå¤±è´¥: {e}")
            import traceback
            self.logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return {
                'success': False,
                'error': str(e),
                'experiment_time': self.experiment_time
            }

    def run_selection_phase(self) -> Dict[str, pd.DataFrame]:
        """
        è¿è¡Œç­›é€‰é˜¶æ®µï¼šä¸ºæ¯ä¸ªç»´åº¦ç”ŸæˆETFæ± 

        Returns:
            å„ç»´åº¦çš„ç­›é€‰ç»“æœ
        """
        self.logger.info("\\n--- ç¬¬ä¸€é˜¶æ®µï¼šç»´åº¦ç­›é€‰ ---")

        # æ‰§è¡Œæ‰¹é‡ç­›é€‰
        selection_results = self.selector.batch_select_all_dimensions(
            target_size=self.target_size
        )

        # ä¿å­˜ç­›é€‰ç»“æœ
        stock_lists_dir = self.output_dir / "stock_lists"
        saved_files = self.selector.save_results(selection_results, str(stock_lists_dir))

        self.logger.info(f"ç­›é€‰é˜¶æ®µå®Œæˆï¼Œå…±ç”Ÿæˆ{len(saved_files)}ä¸ªETFæ± ")

        # è®°å½•ç­›é€‰ç»Ÿè®¡
        selection_stats = {}
        for dimension, df in selection_results.items():
            if len(df) > 0:
                selection_stats[dimension] = {
                    'count': len(df),
                    'min_value': df['dimension_value'].min(),
                    'max_value': df['dimension_value'].max(),
                    'mean_value': df['dimension_value'].mean()
                }
            else:
                selection_stats[dimension] = {'count': 0}

        # ä¿å­˜ç­›é€‰ç»Ÿè®¡
        stats_file = self.output_dir / "selection_stats.csv"
        pd.DataFrame(selection_stats).T.to_csv(stats_file)
        self.logger.info(f"ç­›é€‰ç»Ÿè®¡å·²ä¿å­˜: {stats_file}")

        return selection_results

    def run_backtest_phase(self, selection_results: Dict[str, pd.DataFrame]) -> Dict[str, Dict]:
        """
        è¿è¡Œå›æµ‹é˜¶æ®µï¼šå¯¹æ¯ä¸ªETFæ± æ‰§è¡ŒKAMAç­–ç•¥å›æµ‹

        Args:
            selection_results: ç­›é€‰ç»“æœ

        Returns:
            å„ç»´åº¦çš„å›æµ‹ç»“æœ
        """
        self.logger.info("\\n--- ç¬¬äºŒé˜¶æ®µï¼šç­–ç•¥å›æµ‹ ---")

        backtest_results = {}
        backtest_dir = self.output_dir / "backtest_results"
        backtest_dir.mkdir(exist_ok=True)

        for dimension, df in selection_results.items():
            if len(df) == 0:
                self.logger.warning(f"âš ï¸ {dimension}ç»´åº¦ç­›é€‰ç»“æœä¸ºç©ºï¼Œè·³è¿‡å›æµ‹")
                backtest_results[dimension] = {'success': False, 'error': 'Empty selection'}
                continue

            try:
                self.logger.info(f"æ‰§è¡Œ{dimension}ç»´åº¦å›æµ‹...")

                # å‡†å¤‡ETFåˆ—è¡¨æ–‡ä»¶
                etf_list_file = self.output_dir / "stock_lists" / f"dimension_{dimension}_etf_pool.csv"

                # æ‰§è¡Œå›æµ‹
                result = self._run_single_backtest(dimension, str(etf_list_file))
                backtest_results[dimension] = result

                if result['success']:
                    self.logger.info(f"âœ… {dimension}å›æµ‹æˆåŠŸ")
                else:
                    self.logger.error(f"âŒ {dimension}å›æµ‹å¤±è´¥: {result.get('error', 'Unknown error')}")

            except Exception as e:
                self.logger.error(f"âŒ {dimension}å›æµ‹å¼‚å¸¸: {e}")
                backtest_results[dimension] = {'success': False, 'error': str(e)}

        success_count = sum(1 for r in backtest_results.values() if r.get('success', False))
        self.logger.info(f"å›æµ‹é˜¶æ®µå®Œæˆ: {success_count}/{len(backtest_results)}ä¸ªç»´åº¦æˆåŠŸ")

        return backtest_results

    def _run_single_backtest(self, dimension: str, etf_list_file: str) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ªç»´åº¦çš„å›æµ‹

        Args:
            dimension: ç»´åº¦åç§°
            etf_list_file: ETFåˆ—è¡¨æ–‡ä»¶è·¯å¾„

        Returns:
            å›æµ‹ç»“æœ
        """
        try:
            # æ„å»ºå›æµ‹å‘½ä»¤
            cmd = [
                '/home/zijunliu/miniforge3/condabin/conda', 'run', '-n', 'backtesting',
                'python', str(project_root / "backtest_runner.py"),
                '--stock-list', etf_list_file,
                '--strategy', self.strategy_type,
                '--data-dir', self.data_dir,
                '--output', str(self.output_dir / "backtest_results" / f"dimension_{dimension}"),
                '--save-trades',  # ä¿å­˜äº¤æ˜“è®°å½•
                '--save-returns'  # ä¿å­˜æ”¶ç›Šåºåˆ—
            ]

            self.logger.info(f"å›æµ‹å‘½ä»¤: {' '.join(cmd)}")

            # æ‰§è¡Œå›æµ‹
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd=str(project_root),
                timeout=3600  # 1å°æ—¶è¶…æ—¶
            )

            if result.returncode == 0:
                # è§£æå›æµ‹ç»“æœ
                return self._parse_backtest_result(dimension)
            else:
                return {
                    'success': False,
                    'error': f"å›æµ‹å‘½ä»¤å¤±è´¥ (exit code {result.returncode})",
                    'stderr': result.stderr,
                    'stdout': result.stdout
                }

        except subprocess.TimeoutExpired:
            return {'success': False, 'error': 'å›æµ‹è¶…æ—¶'}
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _parse_backtest_result(self, dimension: str) -> Dict[str, Any]:
        """
        è§£æå›æµ‹ç»“æœæ–‡ä»¶

        Args:
            dimension: ç»´åº¦åç§°

        Returns:
            è§£æåçš„å›æµ‹ç»“æœ
        """
        try:
            # å¯»æ‰¾ç»“æœæ–‡ä»¶
            result_dir = self.output_dir / "backtest_results" / f"dimension_{dimension}"
            result_files = list(result_dir.glob("*_summary.csv"))

            if not result_files:
                return {'success': False, 'error': 'æœªæ‰¾åˆ°å›æµ‹ç»“æœæ–‡ä»¶'}

            # è¯»å–æœ€æ–°çš„ç»“æœæ–‡ä»¶
            result_file = max(result_files, key=lambda x: x.stat().st_mtime)
            df = pd.read_csv(result_file)

            if len(df) == 0:
                return {'success': False, 'error': 'å›æµ‹ç»“æœä¸ºç©º'}

            # æå–å…³é”®æŒ‡æ ‡
            summary = df.iloc[0]  # å–ç¬¬ä¸€è¡Œä½œä¸ºæ±‡æ€»ç»“æœ

            metrics = {
                'total_return': summary.get('Return [%]', 0),
                'sharpe_ratio': summary.get('Sharpe Ratio', 0),
                'max_drawdown': summary.get('Max. Drawdown [%]', 0),
                'win_rate': summary.get('Win Rate [%]', 0),
                'trades_count': summary.get('# Trades', 0),
                'avg_return': summary.get('Avg. Trade [%]', 0),
                'std_return': summary.get('Std. Trade [%]', 0)
            }

            # è®¡ç®—Calmaræ¯”ç‡
            if metrics['max_drawdown'] != 0:
                metrics['calmar_ratio'] = abs(metrics['total_return'] / metrics['max_drawdown'])
            else:
                metrics['calmar_ratio'] = 0

            return {
                'success': True,
                'metrics': metrics,
                'result_file': str(result_file),
                'dimension': dimension
            }

        except Exception as e:
            return {'success': False, 'error': f'è§£æç»“æœå¤±è´¥: {str(e)}'}

    def run_analysis_phase(self, backtest_results: Dict[str, Dict]) -> pd.DataFrame:
        """
        è¿è¡Œåˆ†æé˜¶æ®µï¼šæ±‡æ€»å’Œå¯¹æ¯”å„ç»´åº¦çš„è¡¨ç°

        Args:
            backtest_results: å›æµ‹ç»“æœ

        Returns:
            åˆ†æç»“æœDataFrame
        """
        self.logger.info("\\n--- ç¬¬ä¸‰é˜¶æ®µï¼šç»“æœåˆ†æ ---")

        # æå–æˆåŠŸçš„å›æµ‹ç»“æœ
        analysis_data = []
        for dimension, result in backtest_results.items():
            if result.get('success', False):
                metrics = result['metrics']
                row = {
                    'dimension': dimension,
                    'total_return': metrics['total_return'],
                    'sharpe_ratio': metrics['sharpe_ratio'],
                    'max_drawdown': metrics['max_drawdown'],
                    'calmar_ratio': metrics['calmar_ratio'],
                    'win_rate': metrics['win_rate'],
                    'trades_count': metrics['trades_count'],
                    'avg_return': metrics['avg_return'],
                    'std_return': metrics['std_return']
                }
                analysis_data.append(row)
            else:
                # å¤±è´¥çš„æƒ…å†µä¹Ÿè®°å½•ï¼Œç”¨NaNå¡«å……
                row = {
                    'dimension': dimension,
                    'error': result.get('error', 'Unknown error')
                }
                for metric in ['total_return', 'sharpe_ratio', 'max_drawdown', 'calmar_ratio',
                              'win_rate', 'trades_count', 'avg_return', 'std_return']:
                    row[metric] = np.nan
                analysis_data.append(row)

        # åˆ›å»ºåˆ†æDataFrame
        analysis_df = pd.DataFrame(analysis_data)

        # æŒ‰å¤æ™®æ¯”ç‡æ’åºï¼ˆé™åºï¼‰
        analysis_df = analysis_df.sort_values('sharpe_ratio', ascending=False, na_position='last')
        analysis_df['sharpe_rank'] = range(1, len(analysis_df) + 1)

        # æŒ‰æ€»æ”¶ç›Šæ’åº
        analysis_df_return_sorted = analysis_df.sort_values('total_return', ascending=False, na_position='last')
        analysis_df['return_rank'] = analysis_df_return_sorted.index.map(
            lambda x: analysis_df_return_sorted.index.get_loc(x) + 1
        )

        # ä¿å­˜åˆ†æç»“æœ
        analysis_file = self.output_dir / "analysis" / f"dimension_comparison_{self.experiment_time}.csv"
        analysis_file.parent.mkdir(exist_ok=True)
        analysis_df.to_csv(analysis_file, index=False, encoding='utf-8-sig')

        self.logger.info(f"åˆ†æç»“æœå·²ä¿å­˜: {analysis_file}")

        # æ‰“å°ç®€è¦ç»“æœ
        self.logger.info("\\n=== ç»´åº¦è¡¨ç°æ’å ===")
        self.logger.info("æŒ‰å¤æ™®æ¯”ç‡æ’åº:")
        for _, row in analysis_df.iterrows():
            if not pd.isna(row['sharpe_ratio']):
                self.logger.info(f"{row['sharpe_rank']:2d}. {row['dimension']:20s} - "
                               f"å¤æ™®:{row['sharpe_ratio']:6.3f}, "
                               f"æ”¶ç›Š:{row['total_return']:7.2f}%, "
                               f"å›æ’¤:{row['max_drawdown']:6.2f}%")

        return analysis_df

    def generate_final_report(self, analysis_df: pd.DataFrame) -> str:
        """
        ç”Ÿæˆæœ€ç»ˆå®éªŒæŠ¥å‘Š

        Args:
            analysis_df: åˆ†æç»“æœDataFrame

        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        self.logger.info("\\n--- ç¬¬å››é˜¶æ®µï¼šç”ŸæˆæŠ¥å‘Š ---")

        report_file = self.output_dir / f"DIMENSION_ANALYSIS_REPORT_{self.experiment_time}.md"

        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_content = self._generate_report_content(analysis_df)

        # å†™å…¥æ–‡ä»¶
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)

        self.logger.info(f"å®éªŒæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        return str(report_file)

    def _generate_report_content(self, analysis_df: pd.DataFrame) -> str:
        """ç”ŸæˆæŠ¥å‘Šå†…å®¹"""
        # è·å–æœ€ä½³ç»´åº¦
        best_sharpe = analysis_df.iloc[0] if len(analysis_df) > 0 else None
        best_return = analysis_df.loc[analysis_df['return_rank'] == 1].iloc[0] if len(analysis_df) > 0 else None

        # åˆ†ç»„ç»Ÿè®¡
        main_indicators = ['adx_mean', 'trend_consistency', 'price_efficiency', 'liquidity_score']
        secondary_indicators = ['momentum_3m', 'momentum_12m']

        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
        valid_df = analysis_df[~pd.isna(analysis_df['sharpe_ratio'])]

        report = f"""# ETFç­›é€‰å™¨å•ç»´åº¦æ•ˆæœéªŒè¯å®éªŒæŠ¥å‘Š

**å®éªŒæ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**å®éªŒç‰ˆæœ¬**: {self.experiment_time}

## 1. å®éªŒæ¦‚è¿°

### 1.1 å®éªŒç›®æ ‡
éªŒè¯ETFç­›é€‰ç³»ç»Ÿä¸­å„ä¸ªè¯„åˆ†ç»´åº¦å¯¹KAMAè‡ªé€‚åº”ç­–ç•¥æ”¶ç›Šçš„å•ç‹¬è´¡çŒ®æ•ˆæœï¼Œè¯†åˆ«å…³é”®ç»´åº¦å¹¶ä¸ºæƒé‡ä¼˜åŒ–æä¾›ä¾æ®ã€‚

### 1.2 å®éªŒè®¾è®¡
- **æµ‹è¯•ç»´åº¦**: {len(SingleDimensionSelector.SUPPORTED_DIMENSIONS)}ä¸ª ({', '.join(SingleDimensionSelector.SUPPORTED_DIMENSIONS)})
- **æ± å­è§„æ¨¡**: {self.target_size}åªETF
- **å›æµ‹ç­–ç•¥**: KAMAè‡ªé€‚åº”å‡çº¿ç­–ç•¥
- **æ—¶é—´çª—å£**: 2023-11-01 è‡³ 2025-11-12
- **æˆåŠŸç‡**: {len(valid_df)}/{len(analysis_df)} ({len(valid_df)/len(analysis_df)*100:.1f}%)

## 2. å®éªŒç»“æœ

### 2.1 ç»´åº¦è¡¨ç°æ’å

#### æŒ‰å¤æ™®æ¯”ç‡æ’åº
| æ’å | ç»´åº¦ | å¤æ™®æ¯”ç‡ | æ€»æ”¶ç›Š(%) | æœ€å¤§å›æ’¤(%) | Calmaræ¯”ç‡ | èƒœç‡(%) |
|------|------|---------|-----------|-------------|------------|---------|
"""

        # æ·»åŠ æ’åè¡¨æ ¼
        for _, row in valid_df.iterrows():
            report += f"| {row['sharpe_rank']:2d} | {row['dimension']:20s} | {row['sharpe_ratio']:8.3f} | {row['total_return']:9.2f} | {row['max_drawdown']:11.2f} | {row['calmar_ratio']:10.3f} | {row['win_rate']:7.2f} |\n"

        # æ·»åŠ å…³é”®å‘ç°
        if best_sharpe is not None:
            report += f"""

### 2.2 å…³é”®å‘ç°

**ğŸ† å¤æ™®æ¯”ç‡æœ€ä¼˜ç»´åº¦**: {best_sharpe['dimension']}
- å¤æ™®æ¯”ç‡: {best_sharpe['sharpe_ratio']:.3f}
- æ€»æ”¶ç›Š: {best_sharpe['total_return']:.2f}%
- æœ€å¤§å›æ’¤: {best_sharpe['max_drawdown']:.2f}%
- èƒœç‡: {best_sharpe['win_rate']:.2f}%

"""

        if best_return is not None and best_return['dimension'] != best_sharpe['dimension']:
            report += f"""**ğŸ“ˆ æ€»æ”¶ç›Šæœ€ä¼˜ç»´åº¦**: {best_return['dimension']}
- æ€»æ”¶ç›Š: {best_return['total_return']:.2f}%
- å¤æ™®æ¯”ç‡: {best_return['sharpe_ratio']:.3f}
- æœ€å¤§å›æ’¤: {best_return['max_drawdown']:.2f}%

"""

        # åˆ†ç»„åˆ†æ
        main_df = valid_df[valid_df['dimension'].isin(main_indicators)]
        secondary_df = valid_df[valid_df['dimension'].isin(secondary_indicators)]

        if len(main_df) > 0:
            report += f"""### 2.3 ä¸»è¦æŒ‡æ ‡åˆ†æï¼ˆæ— åæŠ€æœ¯æŒ‡æ ‡ï¼‰

- **å¹³å‡å¤æ™®æ¯”ç‡**: {main_df['sharpe_ratio'].mean():.3f}
- **å¹³å‡æ€»æ”¶ç›Š**: {main_df['total_return'].mean():.2f}%
- **å¹³å‡å›æ’¤**: {main_df['max_drawdown'].mean():.2f}%
- **æœ€ä½³è¡¨ç°**: {main_df.loc[main_df['sharpe_ratio'].idxmax(), 'dimension']} (å¤æ™®æ¯”ç‡ {main_df['sharpe_ratio'].max():.3f})

"""

        if len(secondary_df) > 0:
            report += f"""### 2.4 æ¬¡è¦æŒ‡æ ‡åˆ†æï¼ˆåŠ¨é‡æŒ‡æ ‡ï¼‰

- **å¹³å‡å¤æ™®æ¯”ç‡**: {secondary_df['sharpe_ratio'].mean():.3f}
- **å¹³å‡æ€»æ”¶ç›Š**: {secondary_df['total_return'].mean():.2f}%
- **å¹³å‡å›æ’¤**: {secondary_df['max_drawdown'].mean():.2f}%
- **æœ€ä½³è¡¨ç°**: {secondary_df.loc[secondary_df['sharpe_ratio'].idxmax(), 'dimension']} (å¤æ™®æ¯”ç‡ {secondary_df['sharpe_ratio'].max():.3f})

"""

        # éªŒè¯å‡è®¾
        report += f"""## 3. å‡è®¾éªŒè¯

### 3.1 æ ¸å¿ƒå‡è®¾æ£€éªŒ

"""

        # H1: ADXè¡¨ç°æœ€å¥½
        adx_row = valid_df[valid_df['dimension'] == 'adx_mean']
        if len(adx_row) > 0:
            adx_rank = adx_row.iloc[0]['sharpe_rank']
            h1_result = "âœ… æˆç«‹" if adx_rank <= 2 else "âŒ ä¸æˆç«‹"
            report += f"**H1 - ADXè¶‹åŠ¿å¼ºåº¦è¡¨ç°æœ€ä¼˜**: {h1_result} (å¤æ™®æ¯”ç‡æ’åç¬¬{adx_rank}ä½)\n\n"

        # H2: åŠ¨é‡è¡¨ç°è‰¯å¥½ä½†æœ‰åå·®é£é™©
        if len(secondary_df) > 0:
            momentum_avg_rank = secondary_df['sharpe_rank'].mean()
            h2_result = "âœ… æˆç«‹" if momentum_avg_rank <= 3 else "âš ï¸ éƒ¨åˆ†æˆç«‹"
            report += f"**H2 - åŠ¨é‡æŒ‡æ ‡è¡¨ç°è‰¯å¥½**: {h2_result} (å¹³å‡æ’åç¬¬{momentum_avg_rank:.1f}ä½)\n\n"

        # H3: æ— åæŒ‡æ ‡ç¨³å¥æ€§æ›´å¼º
        if len(main_df) > 0 and len(secondary_df) > 0:
            main_std = main_df['sharpe_ratio'].std()
            secondary_std = secondary_df['sharpe_ratio'].std()
            h3_result = "âœ… æˆç«‹" if main_std < secondary_std else "âŒ ä¸æˆç«‹"
            report += f"**H3 - æ— åæŒ‡æ ‡æ›´ç¨³å¥**: {h3_result} (ä¸»è¦æŒ‡æ ‡æ ‡å‡†å·® {main_std:.3f} vs æ¬¡è¦æŒ‡æ ‡ {secondary_std:.3f})\n\n"

        # å®é™…å»ºè®®
        report += """## 4. å®ç”¨å»ºè®®

### 4.1 æƒé‡ä¼˜åŒ–å»ºè®®

"""

        if len(valid_df) >= 3:
            top3_dimensions = valid_df.head(3)['dimension'].tolist()
            report += f"**æ¨èé‡ç‚¹å…³æ³¨ç»´åº¦**:\n"
            for i, dim in enumerate(top3_dimensions, 1):
                report += f"{i}. {dim}\n"
            report += "\n"

        # ç»“è®º
        if best_sharpe is not None:
            report += f"""### 4.2 é…ç½®å»ºè®®

åŸºäºå®éªŒç»“æœï¼Œå»ºè®®ï¼š

1. **æå‡{best_sharpe['dimension']}æƒé‡** - ä½œä¸ºè¡¨ç°æœ€ä¼˜çš„ç»´åº¦
2. **ä¿æŒæŠ€æœ¯æŒ‡æ ‡ä¸»å¯¼åœ°ä½** - æ— åæŒ‡æ ‡æ•´ä½“è¡¨ç°ç¨³å¥
3. **é€‚åº¦é™ä½ä½è¡¨ç°ç»´åº¦æƒé‡** - ä¼˜åŒ–æ•´ä½“é…ç½®æ•ˆç‡

### 4.3 åç»­ä¼˜åŒ–æ–¹å‘

1. åŸºäºæœ¬å®éªŒç»“æœè°ƒæ•´æƒé‡é…ç½®
2. è€ƒè™‘ç»„åˆæ•ˆåº”çš„è¿›ä¸€æ­¥å®éªŒ
3. éªŒè¯ç»“æœåœ¨ä¸åŒå¸‚åœºç¯å¢ƒä¸‹çš„ç¨³å®šæ€§

"""

        # æŠ€æœ¯é™„å½•
        report += f"""## 5. æŠ€æœ¯é™„å½•

### 5.1 å®éªŒé…ç½®
- é¡¹ç›®æ ¹ç›®å½•: {project_root}
- æ•°æ®ç›®å½•: {self.data_dir}
- è¾“å‡ºç›®å½•: {self.output_dir}
- ç­–ç•¥ç±»å‹: {self.strategy_type}

### 5.2 æ–‡ä»¶æ¸…å•
- ç­›é€‰ç»“æœ: `stock_lists/dimension_*_etf_pool.csv`
- å›æµ‹ç»“æœ: `backtest_results/dimension_*/`
- åˆ†ææ•°æ®: `analysis/dimension_comparison_{self.experiment_time}.csv`

---

**å®éªŒå®Œæˆæ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**æŠ¥å‘Šç”Ÿæˆ**: ETFç­›é€‰å™¨å•ç»´åº¦æ•ˆæœéªŒè¯å®éªŒç³»ç»Ÿ
"""

        return report


def main():
    """ä¸»å‡½æ•°"""
    print("=== ETFç­›é€‰å™¨å•ç»´åº¦æ•ˆæœéªŒè¯å®éªŒ ===")

    try:
        # åˆ›å»ºå®éªŒå®ä¾‹
        experiment = DimensionAnalysisExperiment()

        # è¿è¡Œå®Œæ•´å®éªŒ
        results = experiment.run_experiment()

        if results['success']:
            print(f"\\nğŸ‰ å®éªŒæˆåŠŸå®Œæˆï¼")
            print(f"ğŸ“Š å®éªŒæŠ¥å‘Š: {results['report_path']}")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {experiment.output_dir}")

            # æ˜¾ç¤ºç®€è¦ç»“æœ
            if 'analysis_results' in results:
                analysis_df = results['analysis_results']
                valid_df = analysis_df[~pd.isna(analysis_df['sharpe_ratio'])]
                if len(valid_df) > 0:
                    best_dim = valid_df.iloc[0]
                    print(f"\\nğŸ† æœ€ä¼˜ç»´åº¦: {best_dim['dimension']}")
                    print(f"   å¤æ™®æ¯”ç‡: {best_dim['sharpe_ratio']:.3f}")
                    print(f"   æ€»æ”¶ç›Š: {best_dim['total_return']:.2f}%")
        else:
            print(f"\\nâŒ å®éªŒå¤±è´¥: {results.get('error', 'Unknown error')}")

    except Exception as e:
        print(f"âŒ å®éªŒå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()